{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61094eba",
   "metadata": {},
   "source": [
    "## Minera√ß√£o de Dados Educacionais ‚Äì PISA 2018 (Brasil)\n",
    "\n",
    "Este notebook utiliza tr√™s tabelas centrais: `STU_BRA.xlsx`, `FLT_BRA.xlsx` e `SCH_BRA.xlsx` como base para esta etapa de minera√ß√£o de dados do projeto **Efeito Escola e Gradiente Socioecon√¥mico no Brasil**. Cada arquivo corresponde a um n√≠vel anal√≠tico distinto e complementar (aluno, desempenho, escola), o que organiza a informa√ß√£o, reduz ru√≠do e favorece a consist√™ncia metodol√≥gica. A mesma l√≥gica orienta a sele√ß√£o das vari√°veis em cada tabela.\n",
    "\n",
    "Na tabela `STU_BRA.xlsx` (n√≠vel aluno), a vari√°vel `BELONG` (sentimento de pertencimento) captura o grau em que o estudante se sente parte da comunidade escolar. Algumas fontes pesquisadas sugerem que maior senso de pertencimento se associa a maior engajamento e, em m√©dia, a melhores resultados. Nesse contexto, avaliamos `BELONG` ao lado de `ESCS` e `READ`, uma vez que parece plaus√≠vel que um alto pertencimento atenue o efeito negativo de origens socioecon√¥micas desfavorecidas ao longo do gradiente. Vai saber. Quer dizer, saberemos!\n",
    "\n",
    "Os controles de g√™nero (`ST004D01T`) e de hist√≥rico de repet√™ncia (`REPEAT`) foram inclu√≠dos para tentar separar o efeito do `ESCS` de outras caracter√≠sticas associadas ao desempenho. Cremos que possa haver, entre meninos e meninas, padr√µes distintos de profici√™ncia, e como, popularmente, a repet√™ncia costuma estar associada a escores mais baixos, ao condicionar-mo-nas ao modelo, pretendemos estimar um efeito condicional do `ESCS`, reduzindo a contamina√ß√£o por fatores n√£o diretamente socioecon√¥micos. Reconhecemos, por√©m, que `REPEAT` pode ser, em parte, consequ√™ncia do pr√≥prio `ESCS`; logo, esse controle tende a subestimar o efeito total do contexto socioecon√¥mico, o que deve ser levado em conta na interpreta√ß√£o.\n",
    "\n",
    "A vari√°vel `ESCS` √© um √≠ndice sint√©tico que resume a posi√ß√£o socioecon√¥mica, cultural e educacional da fam√≠lia. Ela √© constru√≠da pela OCDE a partir de modelos de Teoria de Resposta ao Item, combinando informa√ß√£o sobre escolaridade e ocupa√ß√£o dos pais, recursos culturais no domic√≠lio, bens, livros e outros indicadores em uma √∫nica medida cont√≠nua. Trata-se de um √≠ndice do tipo WLE (Estimativa de verossimilhan√ßa ponderada), calculado com base no procedimento descrito no [PISA 2018 Technical Report](https://www.oecd.org/pisa/data/pisa2018technicalreport/) (cap√≠tulo de Scaling Procedures), aplicado tanto √†s profici√™ncias quanto aos √≠ndices derivados dos question√°rios.\n",
    "\n",
    "No banco oficial do PISA, o `ESCS` j√° √© divulgado em uma escala padronizada com m√©dia aproximada igual a 0 e desvio-padr√£o aproximado igual a 1. Para fins de armazenamento nos arquivos, a OCDE aplica uma transforma√ß√£o linear: o valor publicado √© dado por valor_no_arquivo = (valor_original + 5) √ó 1000. Assim, um `ESCS` verdadeiro de `‚àí0,103` aparece como `4897`, enquanto um valor de `+1,2` aparece como `6200`. Por conta disso, n√≥s revertemos esse deslocamento para recuperar a escala oficial aplicando `ESCS = valor_no_arquivo / 1000 - 5`. S√≥ para deixar claro, os fatores 5 e 1000 n√£o s√£o escolhas arbitr√°rias deste estudo, mas a invers√£o exata da codifica√ß√£o adotada pela OCDE, tamb√©m utilizada para outros √≠ndices como DISCLIMA, JOYREAD e SCREADCOMP (documentados no [PISA 2018 Database ‚Äì Codebook e Data Analysis Manual](https://www.oecd.org/pisa/data/2018database/)).\n",
    "\n",
    "Em termos substantivos, valores mais altos de `ESCS` indicam fam√≠lias com maior capital socioecon√¥mico. Neste estudo, tratamo-lo como eixo do gradiente socioecon√¥mico e o coeficiente associado a ele indica como a profici√™ncia em leitura varia em fun√ß√£o da origem social do estudante, servindo de refer√™ncia para quantificar desigualdades educacionais associadas ao contexto socioecon√¥mico.\n",
    "\n",
    "A vari√°vel `READ` representa a profici√™ncia em leitura dos estudantes. Na base `FLT_BRA.xlsx`, o escore √© obtido a partir da combina√ß√£o adequada dos dez valores plaus√≠veis de leitura e dos pesos amostrais correspondentes. Utilizamos `READ` como vari√°vel dependente por ser uma medida padronizada (m√©dia na OCDE ‚âà 500, desvio-padr√£o ‚âà 100), compar√°vel entre alunos e escolas e alinhada ao foco do PISA em compreens√£o leitora.\n",
    "\n",
    "Por fim, `STU_BRA.xlsx` fornece os identificadores dos alunos (`CNTSTUID`) e das escolas (`CNTSCHID`), al√©m de `DISCLIMA` (clima disciplinar) e outras vari√°veis usadas como regressores. Em conjunto, essas informa√ß√µes permitem descrever o gradiente socioecon√¥mico aluno a aluno e conectar esse gradiente √†s caracter√≠sticas das escolas, aproximando a an√°lise tanto de evid√™ncias emp√≠ricas consolidadas quanto das hip√≥teses te√≥ricas que motivam o estudo.\n",
    "\n",
    "A tabela `FLT_BRA.xlsx` complementa o n√≠vel aluno com as vari√°veis relacionadas ao desempenho medido pelo PISA e ao desenho amostral. Ela cont√©m `READ` e `READ.SE`, calculados a partir dos dez valores plaus√≠veis de leitura (`PV1READ`‚Ä¶`PV10READ`) gerados pela OCDE, que aplicam a Teoria de Resposta ao Item para lidar com o fato de cada estudante responder apenas parte dos itens do teste. O valor de `READ` sintetiza a profici√™ncia m√©dia compar√°vel entre alunos e escolas, enquanto `READ.SE` expressa o erro-padr√£o associado a essa estimativa, de modo que erros menores indicam maior precis√£o. A mesma base inclui o peso final do estudante, `SENWT` (*Student Final Weight*), utilizado como fator de expans√£o: como escolas e alunos s√£o amostrados com probabilidades distintas, aplicar `SENWT` em m√©dias, regress√µes e modelos garante que os resultados reflitam a popula√ß√£o nacional de estudantes de 15 anos, e n√£o apenas a amostra observada.\n",
    "\n",
    "Al√©m disso, `FLT_BRA.xlsx` re√∫ne √≠ndices psicom√©tricos que capturam aspectos intrapessoais relevantes para o desempenho em leitura, como `JOYREAD` e `SCREADCOMP`. Esses √≠ndices s√£o derivados do question√°rio, constru√≠dos por escalas WLE e centrados em torno de zero. O √≠ndice `JOYREAD` representa o prazer declarado em ler, enquanto `SCREADCOMP` mede a autoefic√°cia na leitura. Ambos s√£o utilizados para investigar se motiva√ß√£o e autopercep√ß√£o moderam o gradiente socioecon√¥mico: por exemplo, um aluno de baixo `ESCS`, mas com alta motiva√ß√£o ou confian√ßa, pode apresentar desempenho acima do esperado, enquanto baixa autoefic√°cia pode amplificar desigualdades.\n",
    "\n",
    "A planilha `SCH_BRA.xlsx` introduz o n√≠vel de contexto escolar, correspondente ao segundo n√≠vel dos modelos. Para cada `CNTSCHID`, s√£o disponibilizados, entre outros indicadores, os √≠ndices `EDUSHORT` e `STAFFSHORT`, constru√≠dos a partir das respostas dos diretores sobre escassez de materiais pedag√≥gicos e de pessoal qualificado. Os valores originais variam de 1 a 119; ao reescalonarmos (`/10 - 5`), recuperamos uma escala aproximadamente centrada em zero que facilita a interpreta√ß√£o, em que valores positivos indicam maior escassez que a m√©dia da OCDE e valores negativos indicam menor escassez. A base inclui tamb√©m `SC016Q01TA` e `SC016Q02TA`, que expressam os percentuais da receita escolar provenientes de fontes governamentais e de contribui√ß√µes privadas (fam√≠lias, doadores, patroc√≠nios), permitindo caracterizar a composi√ß√£o financeira do ambiente escolar.\n",
    "\n",
    "Esses indicadores s√£o vinculados aos alunos via `CNTSCHID`, o que possibilita testar se condi√ß√µes objetivas de recursos e financiamento moderam a inclina√ß√£o do gradiente socioecon√¥mico e quantificar quanto da vari√¢ncia entre escolas (efeito escola) est√° associada a fatores mensur√°veis de gest√£o e infraestrutura. Combinando as tr√™s bases, √© poss√≠vel modelar o gradiente socioecon√¥mico ponderando corretamente o desenho amostral e explorando fatores intrapessoais e institucionais que podem suavizar ou acentuar o efeito da origem socioecon√¥mica sobre `READ`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de824b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"colorblind\")\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c798ca7d",
   "metadata": {},
   "source": [
    "Importando nossos scripts de apoio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bb941437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando o diret√≥rio scripts ao path do Python\n",
    "\n",
    "scripts_dir = Path.cwd() / \"scripts\"\n",
    "if str(scripts_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(scripts_dir))\n",
    "\n",
    "import read_excel_sheets as les\n",
    "import exploratory as expl\n",
    "import estatisticas as estat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06698fcc",
   "metadata": {},
   "source": [
    "Selecionando as planilhas relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f2faea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"pisa2018\")\n",
    "STU_FILE = BASE_DIR / \"stu\" / \"STU_BRA.xlsx\"\n",
    "FLT_FILE = BASE_DIR / \"flt\" / \"FLT_BRA.xlsx\"\n",
    "SCH_FILE = BASE_DIR / \"sch\" / \"SCH_BRA.xlsx\"\n",
    "\n",
    "for path in (STU_FILE, FLT_FILE, SCH_FILE):\n",
    "    assert path.exists(), f\"Arquivo n√£o encontrado: {path}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30cc409",
   "metadata": {},
   "source": [
    "Conferindo as abas dispon√≠veis em cada planilha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b97bb7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STU_BRA.xlsx -> abas dispon√≠veis: ['data.with.lbl', 'data', 'fields']\n",
      "FLT_BRA.xlsx -> abas dispon√≠veis: ['data.with.lbl', 'data', 'fields']\n",
      "SCH_BRA.xlsx -> abas dispon√≠veis: ['data.with.lbl', 'data', 'fields']\n"
     ]
    }
   ],
   "source": [
    "les.inspect_workbook(STU_FILE)\n",
    "les.inspect_workbook(FLT_FILE)\n",
    "les.inspect_workbook(SCH_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd474fcb",
   "metadata": {},
   "source": [
    "## Features Relevantes\n",
    "\n",
    "Selecionaremos as colunas abaixo, apenas das abas `data` de cada planilha.\n",
    "- `STU_BRA.xlsx` fornece os indicadores de aluno (`ESCS`, `DISCLIMA`, `BELONG`, g√™nero, repet√™ncia etc.).\n",
    "- `FLT_BRA.xlsx` agrega os escores plaus√≠veis de leitura (`READ`) e os pesos amostrais (`SENWT`). Os identificadores (`CNTSTUID`) aparecem deslocados em +50.000 e s√£o alinhados manualmente.\n",
    "- `SCH_BRA.xlsx` traz √≠ndices de contexto escolar (`EDUSHORT`, `STAFFSHORT`), al√©m da composi√ß√£o de financiamento (`SC016Qxx`).\n",
    "\n",
    "\n",
    "Selecionando as colunas relevantes em cada planilha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a4272d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "STU_COLS = [\n",
    "    \"CNTSTUID\", \"CNTSCHID\", \"ESCS\", \"DISCLIMA\", \"BELONG\",\n",
    "    \"ST004D01T\", \"REPEAT\"\n",
    "]\n",
    "FLT_COLS = [\n",
    "    \"CNTSTUID\", \"CNTSCHID\", \"SENWT\", \"READ\", \"READ.SE\",\n",
    "    \"JOYREAD\", \"SCREADCOMP\"\n",
    "]\n",
    "SCH_COLS = [\n",
    "    \"CNTSCHID\", \"SC016Q01TA\", \"SC016Q02TA\", \"EDUSHORT\", \"STAFFSHORT\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a87990",
   "metadata": {},
   "source": [
    "Criando os dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "48c71823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10691, 7), (8311, 7), (597, 5))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu = les.load_sheet(STU_FILE, STU_COLS)\n",
    "flt = les.load_sheet(FLT_FILE, FLT_COLS)\n",
    "sch = les.load_sheet(SCH_FILE, SCH_COLS)\n",
    "\n",
    "stu.shape, flt.shape, sch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce18dfd2",
   "metadata": {},
   "source": [
    "De acordo com a documenta√ß√£o j√° mencionada, o atributo `CNTSTUID` na planilha `FLT` vem com um acr√©scimo de 50.000. Em vez de 7600001, 7600002, etc., os IDs aparecem como 7650001, 7650002, etc. Por conta disso, para regularizar a situa√ß√£o, precisamos subtrair 50.000 nesses IDs. Caso contr√°rio,  o merge aluno‚Äëa‚Äëaluno n√£o funcionar√° corretamente. Na verdade, o merge n√£o funcionar√° de jeito nenhum, porque n√£o haver√° correspond√™ncia entre os IDs. Vejamos isso usando `how=\"outer\"` para reter todos os registros que est√£o s√≥ em stu, s√≥ em flt e os que aparecem nos dois. Isso nos permitir√° medir a qualidade do merge a partir dos percentuais de perda/ganho, por exemplo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e7b724e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVALIA√á√ÉO DO MERGE SEM AJUSTE\n",
      "\n",
      "Compatibilidade dos IDs:\n",
      "   STU - Primeiros CNTSTUID: [7600001, 7600002, 7600005]\n",
      "   FLT - Primeiros CNTSTUID: [7650001, 7650002, 7650003]\n",
      "\n",
      "Diferen√ßa: 50,000\n",
      "\n",
      "Alunos:\n",
      "   Apenas em STU: 10,691 (56.3%)\n",
      "   Apenas em FLT: 8,311 (43.7%)\n",
      "   Combinados (STU x FLT):: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"AVALIA√á√ÉO DO MERGE SEM AJUSTE\\n\")\n",
    "#print(f\"Dimens√µes originais:\")\n",
    "#print(f\"   ‚Ä¢ STU_BRA: {stu.shape[0]:,} alunos √ó {stu.shape[1]} vari√°veis\")\n",
    "#print(f\"   ‚Ä¢ FLT_BRA: {flt.shape[0]:,} alunos √ó {flt.shape[1]} vari√°veis\\n\")\n",
    "\n",
    "# Identificar o problema do deslocamento\n",
    "print(\"Compatibilidade dos IDs:\")\n",
    "print(f\"   STU - Primeiros CNTSTUID: {stu['CNTSTUID'].head(3).tolist()}\")\n",
    "print(f\"   FLT - Primeiros CNTSTUID: {flt['CNTSTUID'].head(3).tolist()}\")\n",
    "print(f\"\\nDiferen√ßa: {flt['CNTSTUID'].iloc[0] - stu['CNTSTUID'].iloc[0]:,}\")\n",
    "\n",
    "merge_diagnostic_raw = stu.merge(\n",
    "    flt, \n",
    "    on=[\"CNTSTUID\", \"CNTSCHID\"], \n",
    "    how=\"outer\", \n",
    "    indicator=True,\n",
    "    suffixes=('_stu', '_flt')\n",
    ")\n",
    "\n",
    "merge_counts_raw = merge_diagnostic_raw['_merge'].value_counts()\n",
    "print(f\"\\nAlunos:\")\n",
    "for status, count in merge_counts_raw.items():\n",
    "    pct = 100 * count / len(merge_diagnostic_raw)\n",
    "    status_label = {\n",
    "        'both': 'Combinados (STU x FLT):',\n",
    "        'left_only': 'Apenas em STU',\n",
    "        'right_only': 'Apenas em FLT'\n",
    "    }.get(status, status)\n",
    "    print(f\"   {status_label}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "#if merge_counts_raw.get('both', 0) == 0:\n",
    "#    print(\"\\nNenhuma combina√ß√£o v√°lida encontrada!\")\n",
    "\n",
    "# Limpar diagn√≥stico preliminar\n",
    "del merge_diagnostic_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b92f479",
   "metadata": {},
   "source": [
    "Ajustando o deslocamento: subtraindo 50000 do CNTSTUID em `FLT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9b97d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiros IDs ap√≥s corre√ß√£o: [7600001, 7600002, 7600003]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flt[\"CNTSTUID\"] = flt[\"CNTSTUID\"] - 50_000\n",
    "print(f\"Primeiros IDs ap√≥s corre√ß√£o: {flt['CNTSTUID'].head(3).tolist()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9d48ca",
   "metadata": {},
   "source": [
    "Vamos repetir o merge, com `how=\"outer\"`, e conferir o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3ec9fe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVALIA√á√ÉO DO MERGE P√ìS-AJUSTE\n",
      "\n",
      "Compatibilidade dos IDs:\n",
      "   STU - Primeiros CNTSTUID: [7600001, 7600002, 7600005]\n",
      "   FLT - Primeiros CNTSTUID: [7600001, 7600002, 7600003]\n",
      "\n",
      "Diferen√ßa: 0\n",
      "\n",
      "Alunos:\n",
      "   Apenas em STU: 5,783 (41.0%)\n",
      "   Combinados (STU x FLT):: 4,908 (34.8%)\n",
      "   Apenas em FLT: 3,403 (24.1%)\n"
     ]
    }
   ],
   "source": [
    "print(\"AVALIA√á√ÉO DO MERGE P√ìS-AJUSTE\\n\")\n",
    "\n",
    "print(\"Compatibilidade dos IDs:\")\n",
    "print(f\"   STU - Primeiros CNTSTUID: {stu['CNTSTUID'].head(3).tolist()}\")\n",
    "print(f\"   FLT - Primeiros CNTSTUID: {flt['CNTSTUID'].head(3).tolist()}\")\n",
    "diferenca = flt['CNTSTUID'].iloc[0] - stu['CNTSTUID'].iloc[0]\n",
    "print(f\"\\nDiferen√ßa: {diferenca:,}\")\n",
    "\n",
    "#if diferenca == 0:\n",
    "#    print(\"IDs alinhados!\\n\")\n",
    "#else:\n",
    "#    print(f\"Ainda h√° desalinhamento de {abs(diferenca):,}\\n\")\n",
    "\n",
    "merge_diagnostic = stu.merge(\n",
    "    flt, \n",
    "    on=[\"CNTSTUID\", \"CNTSCHID\"], \n",
    "    how=\"outer\", \n",
    "    indicator=True,\n",
    "    suffixes=('_stu', '_flt')\n",
    ")\n",
    "\n",
    "merge_counts = merge_diagnostic['_merge'].value_counts()\n",
    "print(\"\\nAlunos:\")\n",
    "for status, count in merge_counts.items():\n",
    "    pct = 100 * count / len(merge_diagnostic)\n",
    "    status_label = {\n",
    "        'both': 'Combinados (STU x FLT):',\n",
    "        'left_only': 'Apenas em STU',\n",
    "        'right_only': 'Apenas em FLT'\n",
    "    }.get(status, status)\n",
    "    print(f\"   {status_label}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Limpar diagn√≥stico preliminar\n",
    "del merge_diagnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17483f49",
   "metadata": {},
   "source": [
    "## An√°lise do merge\n",
    "\n",
    "Se olharmos para o resultado do merge com how=\"inner\", que retorna apenas as linhas onde ambas as chaves (CNTSTUID E CNTSCHID) coincidem nos dois DataFrames: 4.908 alunos, apenas, parece que h√° uma diferen√ßa consider√°vel entre as bases STU e FLT. Ao menos entre os IDs dos alunos. Ainda que em um primeiro momento isso tenha ligado um sinal de alerta em rela√ß√£o √† manuten√ß√£o do JOIN, avaliamos que, apesar da base `FLT` derivar da `STU`, elas n√£o s√£o id√™nticas. `FLT` cont√©m apenas os alunos que participaram do teste de leitura, enquanto que `STU` inclui todos os alunos amostrados, independentemente de terem participado ou n√£o do teste de leitura. Portanto, pareceu-nos adequado e at√© mesmo esperado que FLT seja uma subamostra da base STU. Ou seja, d√° para manter o JOIN, mesmo com a redu√ß√£o do n√∫mero de alunos, j√° que isso nos garante integridade dos dados de profici√™ncia em leitura. Do contr√°rio, ainda que o aluno tenha `ESCS` em `STU`, se ele n√£o tiver `READ` em `FLT`, n√£o poderemos us√°-lo na an√°lise, uma vez que o gradiente socioecon√¥mico depende de ambos os dados. Por tudo isso, seguimos com o merge definitivo.\n",
    "\n",
    "S√≥ para n√£o dizer que n√£o exlicamos o √≥bvio, e pecar por excesso, dizem, √© menos \"ruim\" do que pecar por sua falta, vamos combinar as colunas dos dataframes`stu` (caracter√≠sticas do aluno) com as colunas do dataframe `flt` (escore de leitura, peso amostral, √≠ndices motivacionais) em um  √∫nico dataframe: `students`. A chave do merge s√£o as colunas `CNTSTUID` e `CNTSCHID`, que acabamos de ajeitar, de tal modo que cada aluno s√≥ entra se tiver uma linha correspondente nas duas bases. Para isso usaremos o  `validate=\"one_to_one\"`, que imp√µe uma checagem importante, for√ßando o Pandas a verificar se cada combina√ß√£o de aluno-escola aparece no m√°ximo uma vez em cada DataFrame. **Desse modo, caso haja duplicados, o merge falha, impedindo que propaguemos dados replicados sem perceber.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3fd8beb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNTSTUID</th>\n",
       "      <th>CNTSCHID</th>\n",
       "      <th>ST004D01T</th>\n",
       "      <th>REPEAT</th>\n",
       "      <th>ESCS</th>\n",
       "      <th>DISCLIMA</th>\n",
       "      <th>BELONG</th>\n",
       "      <th>JOYREAD</th>\n",
       "      <th>SCREADCOMP</th>\n",
       "      <th>SENWT</th>\n",
       "      <th>READ</th>\n",
       "      <th>READ.SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7600001</td>\n",
       "      <td>7600614</td>\n",
       "      <td>Male</td>\n",
       "      <td>Did not repeat a  grade</td>\n",
       "      <td>3,353.000</td>\n",
       "      <td>532.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>623.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.308</td>\n",
       "      <td>470.375</td>\n",
       "      <td>22.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7600002</td>\n",
       "      <td>7600190</td>\n",
       "      <td>Female</td>\n",
       "      <td>Did not repeat a  grade</td>\n",
       "      <td>7,479.000</td>\n",
       "      <td>870.000</td>\n",
       "      <td>1,014.000</td>\n",
       "      <td>194.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0.342</td>\n",
       "      <td>432.607</td>\n",
       "      <td>23.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7600010</td>\n",
       "      <td>7600048</td>\n",
       "      <td>Female</td>\n",
       "      <td>Did not repeat a  grade</td>\n",
       "      <td>6,273.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>1,534.000</td>\n",
       "      <td>236.000</td>\n",
       "      <td>54.000</td>\n",
       "      <td>0.525</td>\n",
       "      <td>428.324</td>\n",
       "      <td>31.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7600020</td>\n",
       "      <td>7600444</td>\n",
       "      <td>Male</td>\n",
       "      <td>Repeated a  grade</td>\n",
       "      <td>1,830.000</td>\n",
       "      <td>313.000</td>\n",
       "      <td>1,185.000</td>\n",
       "      <td>393.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>0.658</td>\n",
       "      <td>378.231</td>\n",
       "      <td>24.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7600022</td>\n",
       "      <td>7600047</td>\n",
       "      <td>Male</td>\n",
       "      <td>Repeated a  grade</td>\n",
       "      <td>1,533.000</td>\n",
       "      <td>63.000</td>\n",
       "      <td>392.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>48.000</td>\n",
       "      <td>0.511</td>\n",
       "      <td>419.672</td>\n",
       "      <td>16.979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNTSTUID  CNTSCHID ST004D01T                   REPEAT      ESCS  DISCLIMA  \\\n",
       "0   7600001   7600614      Male  Did not repeat a  grade 3,353.000   532.000   \n",
       "1   7600002   7600190    Female  Did not repeat a  grade 7,479.000   870.000   \n",
       "2   7600010   7600048    Female  Did not repeat a  grade 6,273.000    47.000   \n",
       "3   7600020   7600444      Male        Repeated a  grade 1,830.000   313.000   \n",
       "4   7600022   7600047      Male        Repeated a  grade 1,533.000    63.000   \n",
       "\n",
       "     BELONG  JOYREAD  SCREADCOMP  SENWT    READ  READ.SE  \n",
       "0       NaN  623.000         NaN  0.308 470.375   22.412  \n",
       "1 1,014.000  194.000      16.000  0.342 432.607   23.037  \n",
       "2 1,534.000  236.000      54.000  0.525 428.324   31.055  \n",
       "3 1,185.000  393.000      35.000  0.658 378.231   24.029  \n",
       "4   392.000   14.000      48.000  0.511 419.672   16.979  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students = (\n",
    "    stu.merge(flt, on=[\"CNTSTUID\", \"CNTSCHID\"], how=\"inner\", validate=\"one_to_one\")\n",
    ")\n",
    "\n",
    "students.shape\n",
    "students.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d1421a",
   "metadata": {},
   "source": [
    "Logo em seguida precisaremos restaurar a escala original de alguns √≠ndices, mas antes disso vamos inspecionar os dados √∫nicos nas vari√°veis categ√≥ricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3c68bb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vari√°veis categ√≥ricas: ST004D01T, REPEAT \n",
      "\n",
      "[ST004D01T]  (n√≠veis: 2, missing: 0)\n",
      "  Female                          2533  ( 51.6%)\n",
      "  Male                            2375  ( 48.4%)\n",
      "\n",
      "[REPEAT]  (n√≠veis: 2, missing: 111)\n",
      "  Did not repeat a  grade         3316  ( 67.6%)\n",
      "  Repeated a  grade               1481  ( 30.2%)\n",
      "  <NaN>                            111  (  2.3%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expl.resumo_categoricas(students)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d47c966",
   "metadata": {},
   "source": [
    "### Reescalonamento dos √çndices WLE\n",
    "\n",
    "Como mencionado, precisamos **reescalar os dados** para recuperar os valores originais daqueles √≠ndices WLE selecionados, tal como definidos pela OCDE. Vejamos a l√≥gica para interpreta√ß√£o de cada vari√°vel.\n",
    "\n",
    "#### `ESCS`\n",
    "\n",
    "Exemplo de reescalonamento:\n",
    "\n",
    "* Valor original no arquivo: `4897`\n",
    "* Divis√£o por 1000: `4897 / 1000 = 4.897`\n",
    "* Subtra√ß√£o de 5: `4.897 - 5 = -0.103`\n",
    "\n",
    "Interpreta√ß√£o:\n",
    "\n",
    "* `-0.103` ‚Üí fam√≠lia levemente abaixo da m√©dia da OCDE\n",
    "* `+1.2` ‚Üí fam√≠lia bem acima da m√©dia (alto status)\n",
    "* `-2.0` ‚Üí fam√≠lia em situa√ß√£o muito vulner√°vel\n",
    "\n",
    "\n",
    "#### `DISCLIMA`\n",
    "\n",
    "Exemplo de reescalonamento:\n",
    "\n",
    "* Valor original: `478`\n",
    "* Divis√£o por 100: `478 / 100 = 4.78`\n",
    "* Subtra√ß√£o de 5: `4.78 - 5 = -0.22`\n",
    "\n",
    "Interpreta√ß√£o:\n",
    "\n",
    "* Valores negativos ‚Üí clima mais ordenado que a m√©dia\n",
    "* Valores positivos ‚Üí clima mais problem√°tico\n",
    "* Exemplo: `-0.22` indica disciplina ligeiramente melhor que a m√©dia\n",
    "\n",
    "#### `JOYREAD`\n",
    "\n",
    "Exemplo de reescalonamento:\n",
    "\n",
    "* Valor original: `530`\n",
    "* Divis√£o por 100: `530 / 100 = 5.30`\n",
    "* Subtra√ß√£o de 5: `5.30 - 5 = +0.30`\n",
    "\n",
    "Interpreta√ß√£o:\n",
    "\n",
    "* `+0.30` ‚Üí gosta mais de ler que a m√©dia da OCDE\n",
    "* `-0.50` ‚Üí gosta menos de ler\n",
    "* Valores t√≠picos: aproximadamente de `-3` a `+3`\n",
    "\n",
    "#### `SCREADCOMP`\n",
    "\n",
    "Exemplo de reescalonamento:\n",
    "\n",
    "* Valor original: `462`\n",
    "* Divis√£o por 100: `462 / 100 = 4.62`\n",
    "* Subtra√ß√£o de 5: `4.62 - 5 = -0.38`\n",
    "\n",
    "Interpreta√ß√£o:\n",
    "\n",
    "* `-0.38` ‚Üí confian√ßa abaixo da m√©dia na capacidade de ler\n",
    "* `+1.0` ‚Üí alta autoefic√°cia\n",
    "* Pode moderar o efeito do `ESCS` (um aluno em contexto pobre, mas confiante, pode apresentar melhor desempenho do que o esperado pelo gradiente socioecon√¥mico)\n",
    "\n",
    "#### `BELONG`\n",
    "\n",
    "Exemplo de reescalonamento:\n",
    "\n",
    "* Valor original: `980`\n",
    "* Divis√£o por 100: `980 / 100 = 9.80`\n",
    "* **Sem** subtra√ß√£o de 5\n",
    "\n",
    "Interpreta√ß√£o:\n",
    "\n",
    "* `9.80` ‚Üí forte senso de pertencimento √† escola\n",
    "* `5.00` ‚Üí pertencimento moderado\n",
    "* `2.00` ‚Üí sente-se exclu√≠do ou isolado\n",
    "* Hip√≥tese: alto pertencimento pode amortecer o efeito negativo de baixo `ESCS`\n",
    "\n",
    "### Vari√°veis Categ√≥ricas Codificadas (`dummies`)\n",
    "\n",
    "#### `GENDER` ‚Üí `gender_male`\n",
    "\n",
    "* Valor original: `\"Male\"` ou `\"Female\"`\n",
    "* Compara√ß√£o l√≥gica: `\"Male\" == 'Male'` ‚Üí `True`; `\"Female\" == 'Male'` ‚Üí `False`\n",
    "* Convers√£o para inteiro: `True ‚Üí 1`, `False ‚Üí 0`\n",
    "\n",
    "Valores finais:\n",
    "\n",
    "* `1` = Menino (masculino)\n",
    "* `0` = Menina (feminino)\n",
    "\n",
    "\n",
    "#### `REPEAT` ‚Üí `repeat_flag`\n",
    "\n",
    "* Valor original:\n",
    "\n",
    "  * `\"Repeated a  grade\"`\n",
    "  * `\"Did not repeat a  grade\"`\n",
    "  * `NaN` (sem informa√ß√£o)\n",
    "\n",
    "* Recodifica√ß√£o l√≥gica:\n",
    "\n",
    "  * `repeat_flag = 1` se `REPEAT == \"Repeated a  grade\"`\n",
    "  * `repeat_flag = 0` se `REPEAT == \"Did not repeat a  grade\"`\n",
    "  * `repeat_flag = 2` se `REPEAT` estiver ausente\n",
    "\n",
    "Valores finais:\n",
    "\n",
    "* `1` = Repetiu pelo menos uma s√©rie\n",
    "* `0` = Nunca repetiu\n",
    "* `2` = Informa√ß√£o ausente (casos mantidos como *missing* e tratados como categoria pr√≥pria)\n",
    "\n",
    "\n",
    "### üìà Resumo Visual dos Valores Esperados\n",
    "\n",
    "| Vari√°vel         | Transforma√ß√£o            | Escala final               | Exemplo             |\n",
    "| ---------------- | ------------------------ | -------------------------- | ------------------- |\n",
    "| `escs_std`       | `/1000 - 5`              | ‚âà -3 a +3 (m√©dia = 0)      | `-0.103`            |\n",
    "| `disclima_std`   | `/100 - 5`               | ‚âà -5 a +5 (m√©dia = 0)      | `-0.22`             |\n",
    "| `joyread_std`    | `/100 - 5`               | ‚âà -3 a +3 (m√©dia = 0)      | `+0.30`             |\n",
    "| `screadcomp_std` | `/100 - 5`               | ‚âà -3 a +3 (m√©dia = 0)      | `-0.38`             |\n",
    "| `belong_index`   | `/100`                   | 0 a 10 (n√£o centrada em 0) | `9.80`              |\n",
    "| `gender_male`    | `== \"Male\"`              | 0 ou 1                     | `1` (menino)        |\n",
    "| `repeat_flag`    | `== \"Repeated a  grade\"` | 0, 1 ou `2`                | `0` (nunca repetiu) |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f72675",
   "metadata": {},
   "source": [
    "Vamos fazer uma c√≥pia por seguran√ßa, mantendo o nome do dataframe como `students` mesmo, que fica visualmente mais agrad√°vel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "38620bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_raw = students.copy()  # backup do dado bruto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c8c7e2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNTSTUID</th>\n",
       "      <th>CNTSCHID</th>\n",
       "      <th>ST004D01T</th>\n",
       "      <th>REPEAT</th>\n",
       "      <th>ESCS</th>\n",
       "      <th>DISCLIMA</th>\n",
       "      <th>BELONG</th>\n",
       "      <th>JOYREAD</th>\n",
       "      <th>SCREADCOMP</th>\n",
       "      <th>SENWT</th>\n",
       "      <th>READ</th>\n",
       "      <th>READ.SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7600001</td>\n",
       "      <td>7600614</td>\n",
       "      <td>Male</td>\n",
       "      <td>Did not repeat a  grade</td>\n",
       "      <td>3,353.000</td>\n",
       "      <td>532.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>623.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.308</td>\n",
       "      <td>470.375</td>\n",
       "      <td>22.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7600002</td>\n",
       "      <td>7600190</td>\n",
       "      <td>Female</td>\n",
       "      <td>Did not repeat a  grade</td>\n",
       "      <td>7,479.000</td>\n",
       "      <td>870.000</td>\n",
       "      <td>1,014.000</td>\n",
       "      <td>194.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0.342</td>\n",
       "      <td>432.607</td>\n",
       "      <td>23.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7600010</td>\n",
       "      <td>7600048</td>\n",
       "      <td>Female</td>\n",
       "      <td>Did not repeat a  grade</td>\n",
       "      <td>6,273.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>1,534.000</td>\n",
       "      <td>236.000</td>\n",
       "      <td>54.000</td>\n",
       "      <td>0.525</td>\n",
       "      <td>428.324</td>\n",
       "      <td>31.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7600020</td>\n",
       "      <td>7600444</td>\n",
       "      <td>Male</td>\n",
       "      <td>Repeated a  grade</td>\n",
       "      <td>1,830.000</td>\n",
       "      <td>313.000</td>\n",
       "      <td>1,185.000</td>\n",
       "      <td>393.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>0.658</td>\n",
       "      <td>378.231</td>\n",
       "      <td>24.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7600022</td>\n",
       "      <td>7600047</td>\n",
       "      <td>Male</td>\n",
       "      <td>Repeated a  grade</td>\n",
       "      <td>1,533.000</td>\n",
       "      <td>63.000</td>\n",
       "      <td>392.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>48.000</td>\n",
       "      <td>0.511</td>\n",
       "      <td>419.672</td>\n",
       "      <td>16.979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNTSTUID  CNTSCHID ST004D01T                   REPEAT      ESCS  DISCLIMA  \\\n",
       "0   7600001   7600614      Male  Did not repeat a  grade 3,353.000   532.000   \n",
       "1   7600002   7600190    Female  Did not repeat a  grade 7,479.000   870.000   \n",
       "2   7600010   7600048    Female  Did not repeat a  grade 6,273.000    47.000   \n",
       "3   7600020   7600444      Male        Repeated a  grade 1,830.000   313.000   \n",
       "4   7600022   7600047      Male        Repeated a  grade 1,533.000    63.000   \n",
       "\n",
       "     BELONG  JOYREAD  SCREADCOMP  SENWT    READ  READ.SE  \n",
       "0       NaN  623.000         NaN  0.308 470.375   22.412  \n",
       "1 1,014.000  194.000      16.000  0.342 432.607   23.037  \n",
       "2 1,534.000  236.000      54.000  0.525 428.324   31.055  \n",
       "3 1,185.000  393.000      35.000  0.658 378.231   24.029  \n",
       "4   392.000   14.000      48.000  0.511 419.672   16.979  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students = students_raw.copy()  # dataset de trabalho\n",
    "students.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1566ca66",
   "metadata": {},
   "source": [
    "Agora vamos escalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "40e1dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "students[\"escs_std\"] = students[\"ESCS\"] / 1000 - 5  # √≠ndice socioecon√¥mico centrado em 0\n",
    "students[\"disclima_std\"] = students[\"DISCLIMA\"] / 100 - 5  # clima disciplinar (‚âà-5 a +5)\n",
    "students[\"joyread_std\"] = students[\"JOYREAD\"] / 100 - 5\n",
    "students[\"screadcomp_std\"] = students[\"SCREADCOMP\"] / 100 - 5\n",
    "students[\"belong_index\"] = students[\"BELONG\"] / 100  # escala 0-10 (bem-estar)\n",
    "\n",
    "# G√™nero: 1 = menino, 0 = menina\n",
    "students[\"gender_male\"] = (students[\"ST004D01T\"] == \"Male\").astype(\"int8\")\n",
    "\n",
    "# Repet√™ncia: 0 = n√£o repetiu, 1 = repetiu, 2 = sem informa√ß√£o\n",
    "students[\"repeat_flag\"] = students[\"REPEAT\"].map({\n",
    "    \"Did not repeat a  grade\": 0,\n",
    "    \"Repeated a  grade\": 1\n",
    "})\n",
    "students[\"repeat_flag\"] = students[\"repeat_flag\"].fillna(2).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "784f5dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNTSTUID</th>\n",
       "      <th>CNTSCHID</th>\n",
       "      <th>ST004D01T</th>\n",
       "      <th>REPEAT</th>\n",
       "      <th>ESCS</th>\n",
       "      <th>DISCLIMA</th>\n",
       "      <th>BELONG</th>\n",
       "      <th>JOYREAD</th>\n",
       "      <th>SCREADCOMP</th>\n",
       "      <th>SENWT</th>\n",
       "      <th>READ</th>\n",
       "      <th>READ.SE</th>\n",
       "      <th>escs_std</th>\n",
       "      <th>disclima_std</th>\n",
       "      <th>joyread_std</th>\n",
       "      <th>screadcomp_std</th>\n",
       "      <th>belong_index</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>repeat_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7600001</td>\n",
       "      <td>7600614</td>\n",
       "      <td>Male</td>\n",
       "      <td>Did not repeat a  grade</td>\n",
       "      <td>3,353.000</td>\n",
       "      <td>532.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>623.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.308</td>\n",
       "      <td>470.375</td>\n",
       "      <td>22.412</td>\n",
       "      <td>-1.647</td>\n",
       "      <td>0.320</td>\n",
       "      <td>1.230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7600002</td>\n",
       "      <td>7600190</td>\n",
       "      <td>Female</td>\n",
       "      <td>Did not repeat a  grade</td>\n",
       "      <td>7,479.000</td>\n",
       "      <td>870.000</td>\n",
       "      <td>1,014.000</td>\n",
       "      <td>194.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0.342</td>\n",
       "      <td>432.607</td>\n",
       "      <td>23.037</td>\n",
       "      <td>2.479</td>\n",
       "      <td>3.700</td>\n",
       "      <td>-3.060</td>\n",
       "      <td>-4.840</td>\n",
       "      <td>10.140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7600010</td>\n",
       "      <td>7600048</td>\n",
       "      <td>Female</td>\n",
       "      <td>Did not repeat a  grade</td>\n",
       "      <td>6,273.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>1,534.000</td>\n",
       "      <td>236.000</td>\n",
       "      <td>54.000</td>\n",
       "      <td>0.525</td>\n",
       "      <td>428.324</td>\n",
       "      <td>31.055</td>\n",
       "      <td>1.273</td>\n",
       "      <td>-4.530</td>\n",
       "      <td>-2.640</td>\n",
       "      <td>-4.460</td>\n",
       "      <td>15.340</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7600020</td>\n",
       "      <td>7600444</td>\n",
       "      <td>Male</td>\n",
       "      <td>Repeated a  grade</td>\n",
       "      <td>1,830.000</td>\n",
       "      <td>313.000</td>\n",
       "      <td>1,185.000</td>\n",
       "      <td>393.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>0.658</td>\n",
       "      <td>378.231</td>\n",
       "      <td>24.029</td>\n",
       "      <td>-3.170</td>\n",
       "      <td>-1.870</td>\n",
       "      <td>-1.070</td>\n",
       "      <td>-4.650</td>\n",
       "      <td>11.850</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7600022</td>\n",
       "      <td>7600047</td>\n",
       "      <td>Male</td>\n",
       "      <td>Repeated a  grade</td>\n",
       "      <td>1,533.000</td>\n",
       "      <td>63.000</td>\n",
       "      <td>392.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>48.000</td>\n",
       "      <td>0.511</td>\n",
       "      <td>419.672</td>\n",
       "      <td>16.979</td>\n",
       "      <td>-3.467</td>\n",
       "      <td>-4.370</td>\n",
       "      <td>-4.860</td>\n",
       "      <td>-4.520</td>\n",
       "      <td>3.920</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNTSTUID  CNTSCHID ST004D01T                   REPEAT      ESCS  DISCLIMA  \\\n",
       "0   7600001   7600614      Male  Did not repeat a  grade 3,353.000   532.000   \n",
       "1   7600002   7600190    Female  Did not repeat a  grade 7,479.000   870.000   \n",
       "2   7600010   7600048    Female  Did not repeat a  grade 6,273.000    47.000   \n",
       "3   7600020   7600444      Male        Repeated a  grade 1,830.000   313.000   \n",
       "4   7600022   7600047      Male        Repeated a  grade 1,533.000    63.000   \n",
       "\n",
       "     BELONG  JOYREAD  SCREADCOMP  SENWT    READ  READ.SE  escs_std  \\\n",
       "0       NaN  623.000         NaN  0.308 470.375   22.412    -1.647   \n",
       "1 1,014.000  194.000      16.000  0.342 432.607   23.037     2.479   \n",
       "2 1,534.000  236.000      54.000  0.525 428.324   31.055     1.273   \n",
       "3 1,185.000  393.000      35.000  0.658 378.231   24.029    -3.170   \n",
       "4   392.000   14.000      48.000  0.511 419.672   16.979    -3.467   \n",
       "\n",
       "   disclima_std  joyread_std  screadcomp_std  belong_index  gender_male  \\\n",
       "0         0.320        1.230             NaN           NaN            1   \n",
       "1         3.700       -3.060          -4.840        10.140            0   \n",
       "2        -4.530       -2.640          -4.460        15.340            0   \n",
       "3        -1.870       -1.070          -4.650        11.850            1   \n",
       "4        -4.370       -4.860          -4.520         3.920            1   \n",
       "\n",
       "   repeat_flag  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3806c",
   "metadata": {},
   "source": [
    "Vamos remover as colunas desnecess√°rias (originais) e renomear as novas para manter a consist√™cias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1e3953df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNTSTUID</th>\n",
       "      <th>CNTSCHID</th>\n",
       "      <th>ST004D01T</th>\n",
       "      <th>REPEAT</th>\n",
       "      <th>ESCS</th>\n",
       "      <th>DISCLIMA</th>\n",
       "      <th>BELONG</th>\n",
       "      <th>JOYREAD</th>\n",
       "      <th>SCREADCOMP</th>\n",
       "      <th>SENWT</th>\n",
       "      <th>READ</th>\n",
       "      <th>READ.SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7600001</td>\n",
       "      <td>7600614</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.647</td>\n",
       "      <td>0.320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.308</td>\n",
       "      <td>470.375</td>\n",
       "      <td>22.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7600002</td>\n",
       "      <td>7600190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.479</td>\n",
       "      <td>3.700</td>\n",
       "      <td>10.140</td>\n",
       "      <td>-3.060</td>\n",
       "      <td>-4.840</td>\n",
       "      <td>0.342</td>\n",
       "      <td>432.607</td>\n",
       "      <td>23.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7600010</td>\n",
       "      <td>7600048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.273</td>\n",
       "      <td>-4.530</td>\n",
       "      <td>15.340</td>\n",
       "      <td>-2.640</td>\n",
       "      <td>-4.460</td>\n",
       "      <td>0.525</td>\n",
       "      <td>428.324</td>\n",
       "      <td>31.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7600020</td>\n",
       "      <td>7600444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.170</td>\n",
       "      <td>-1.870</td>\n",
       "      <td>11.850</td>\n",
       "      <td>-1.070</td>\n",
       "      <td>-4.650</td>\n",
       "      <td>0.658</td>\n",
       "      <td>378.231</td>\n",
       "      <td>24.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7600022</td>\n",
       "      <td>7600047</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.467</td>\n",
       "      <td>-4.370</td>\n",
       "      <td>3.920</td>\n",
       "      <td>-4.860</td>\n",
       "      <td>-4.520</td>\n",
       "      <td>0.511</td>\n",
       "      <td>419.672</td>\n",
       "      <td>16.979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNTSTUID  CNTSCHID  ST004D01T  REPEAT   ESCS  DISCLIMA  BELONG  JOYREAD  \\\n",
       "0   7600001   7600614          1       0 -1.647     0.320     NaN    1.230   \n",
       "1   7600002   7600190          0       0  2.479     3.700  10.140   -3.060   \n",
       "2   7600010   7600048          0       0  1.273    -4.530  15.340   -2.640   \n",
       "3   7600020   7600444          1       1 -3.170    -1.870  11.850   -1.070   \n",
       "4   7600022   7600047          1       1 -3.467    -4.370   3.920   -4.860   \n",
       "\n",
       "   SCREADCOMP  SENWT    READ  READ.SE  \n",
       "0         NaN  0.308 470.375   22.412  \n",
       "1      -4.840  0.342 432.607   23.037  \n",
       "2      -4.460  0.525 428.324   31.055  \n",
       "3      -4.650  0.658 378.231   24.029  \n",
       "4      -4.520  0.511 419.672   16.979  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remover colunas originais brutas que j√° t√™m vers√£o transformada\n",
    "cols_drop = [\n",
    "    \"ESCS\", \"DISCLIMA\", \"JOYREAD\", \"SCREADCOMP\", \"BELONG\",\n",
    "    \"ST004D01T\", \"REPEAT\"\n",
    "]\n",
    "\n",
    "students = students.drop(columns=cols_drop)\n",
    "\n",
    "# Renomeaando as colunas novas para manter o mesmo esquema de nomes\n",
    "\n",
    "students = students.rename(columns={\n",
    "    \"escs_std\": \"ESCS\",              # √≠ndice socioecon√¥mico padronizado\n",
    "    \"disclima_std\": \"DISCLIMA\",      # clima disciplinar padronizado\n",
    "    \"joyread_std\": \"JOYREAD\",        # prazer pela leitura padronizado\n",
    "    \"screadcomp_std\": \"SCREADCOMP\",  # autoefic√°cia em leitura padronizada\n",
    "    \"belong_index\": \"BELONG\",        # pertencimento (0‚Äì10)\n",
    "    \"gender_male\": \"ST004D01T\",      # 1 = menino, 0 = menina\n",
    "    \"repeat_flag\": \"REPEAT\"          # 0 = n√£o repetiu, 1 = repetiu, 2 = sem info\n",
    "})\n",
    "\n",
    "# Reorganizando as colunas na ordem do schema original\n",
    "\n",
    "cols_order = [\n",
    "    \"CNTSTUID\", \"CNTSCHID\",\n",
    "    \"ST004D01T\", \"REPEAT\",\n",
    "    \"ESCS\", \"DISCLIMA\", \"BELONG\", \"JOYREAD\", \"SCREADCOMP\",\n",
    "    \"SENWT\", \"READ\", \"READ.SE\"\n",
    "]\n",
    "\n",
    "students = students[cols_order]\n",
    "\n",
    "students.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b102def",
   "metadata": {},
   "source": [
    "Como voc√™ deve ter percebido, preferimos manter os dados ausentes em `REPEAT`, tratando-os como categoria (2) por que adiante podemos inclu√≠-los tanto em uma quanto em outra, de tal modo que podemos avaliar a repet√™ncia somando os (n√£o informados) aos qque repetiram, bem como aos que n√£o repetiram. Cremos que, com isso, podemos capturar nuances que seriam perdidas caso fossem removidos. Contudo, a mesma l√≥gica n√£o se aplica as demais vari√°veis (veja abaixo), onde os dados ausentes devem ser tratados via de regra, pela m√©dia, mediana ou por uma imputa√ß√£o m√∫ltipla, em vez de serem exclu√≠dos das an√°lises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8bee2efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNTSTUID         0\n",
       "CNTSCHID         0\n",
       "ST004D01T        0\n",
       "REPEAT           0\n",
       "ESCS           106\n",
       "DISCLIMA       266\n",
       "BELONG        1114\n",
       "JOYREAD        478\n",
       "SCREADCOMP     732\n",
       "SENWT            0\n",
       "READ             0\n",
       "READ.SE          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c852c6e",
   "metadata": {},
   "source": [
    "Entretanto, por mais que essa decis√£o pare√ßa simples, principalmente para o caso de `ESCS`, cujo n√∫mero de ausentes √© percentualmente baixo, para formalizar nossa escolha avaliamos as tr√™s estrat√©gias cl√°ssicas mencionadas: **exclus√£o de casos**, **imputa√ß√£o simples (m√©dia/mediana)** e **imputa√ß√£o m√∫ltipla**. Cada uma delas parte de pressupostos distintos sobre o mecanismo que gera os dados ausentes, o que impacta, de forma direta e desigual, a validade dos resultados.\n",
    "\n",
    "Para encurtar a conversa, por que simplesmente n√£o criamos uma categoria ‚Äúfaltante‚Äù, como fizemos em `REPEAT`? Porque, naquele caso, transformar o ausente em uma categoria expl√≠cita (2) √© plaus√≠vel: `REPEAT` √© uma vari√°vel categ√≥rica, e o grupo ‚Äún√£o informado‚Äù pode ser tratado como categoria substantivamente interpret√°vel ou usado em an√°lises de sensibilidade (agregando-o a quem repetiu, a quem n√£o repetiu, ou mantendo-o separado).\n",
    "\n",
    "Essa l√≥gica, por√©m, **n√£o se aplica** √†s demais vari√°veis, cujos indicadores foram constru√≠dos como **√≠ndices cont√≠nuos**, muitas vezes com propriedades m√©tricas definidas (por exemplo, sob modelos de Teoria de Resposta ao Item). Criar neles uma categoria ‚Äúfaltante‚Äù equivaleria a inventar um n√≠vel artificial que n√£o existe na escala original. Intuitivamente, isso desloca a r√©gua sem mudar o fen√¥meno. Tecnicamente, tende a distorcer a m√©trica, quebrar interpreta√ß√µes e introduzir descontinuidades esp√∫rias.\n",
    "\n",
    "Seria como, em uma escala de profici√™ncia de leitura, adicionar um ponto ‚Äú666 = n√£o respondeu‚Äù e exigir que o modelo trate esse valor como se fosse um n√≠vel real de desempenho. Computacionalmente funciona; conceitualmente √© torto. A literatura metodol√≥gica converge em desaconselhar esse tipo de codifica√ß√£o: em vari√°veis cont√≠nuas, √© mais adequado imputar valores ausentes a partir da informa√ß√£o observada ou modelar explicitamente o mecanismo de aus√™ncia, em vez de criar categorias fict√≠cias.\n",
    "\n",
    "Mas quando a exclus√£o √© aceit√°vel ent√£o, j√° que falamos que no caso de `ESCS` poder√≠amos faz√™-lo? A√≠ que o bicho pega. A decis√£o entre excluir ou imputar dados ausentes depende do **mecanismo de missing** subjacente, que pode ser classificado em tr√™s tipos principais:  MCAR, MAR e MNAR.\n",
    "\n",
    "De forma resumida:\n",
    "\n",
    "* **MCAR (Missing Completely At Random)**:\n",
    "  A probabilidade de um dado estar ausente **n√£o depende** nem de valores observados, nem dos n√£o observados. O missing √© puro azar.\n",
    "  ‚Üí Aqui, a exclus√£o de casos √© estatisticamente ‚Äúlimpa‚Äù: n√£o gera vi√©s, apenas reduz o tamanho da amostra.\n",
    "\n",
    "* **MAR (Missing At Random)**:\n",
    "  A probabilidade de aus√™ncia **depende de outras vari√°veis observadas**, mas n√£o do valor verdadeiro faltante, depois de controladas essas vari√°veis.\n",
    "  Ex.: alunos com determinado perfil socioecon√¥mico ou em certas escolas t√™m maior chance de n√£o responder `JOYREAD`.\n",
    "  ‚Üí Exclus√£o simples j√° pode induzir vi√©s; m√©todos como imputa√ß√£o m√∫ltipla tornam-se prefer√≠veis.\n",
    "\n",
    "* **MNAR (Missing Not At Random)**:\n",
    "  A probabilidade de aus√™ncia **depende do pr√≥prio valor ausente** (ou de algo n√£o observado).\n",
    "  Ex.: alunos com baix√≠ssima motiva√ß√£o para leitura evitam responder itens sobre leitura.\n",
    "  ‚Üí Nesse caso, tanto exclus√£o quanto imputa√ß√µes ing√™nuas podem ser enviesadas; idealmente, precisa-se de modelos mais sofisticados ou an√°lises de sensibilidade.\n",
    "\n",
    "Na pr√°tica aplicada em educa√ß√£o, parece que assumir `MCAR` √© quase sempre otimista demais, mas n√£o √© s√≥ isso e, ainda que n√£o exista um ‚Äúbala de prata‚Äù, algumas **regras de bolso razo√°veis** ajudam, como por exemplo:\n",
    "\n",
    "* At√© **‚âà5% de ausentes**, sob algo pr√≥ximo de MCAR, a **exclus√£o de casos √© geralmente aceit√°vel**.\n",
    "* Entre **5% e 10%**, exige mais cautela: exclus√£o pode ser usada em an√°lises simples, mas j√° vale considerar imputa√ß√£o, sobretudo se a vari√°vel for central.\n",
    "* Acima de **10%**, especialmente quando h√° ind√≠cios de MAR/MNAR, a exclus√£o sistem√°tica tende a produzir vieses relevantes e perda substantiva de poder estat√≠stico; aqui, **imputa√ß√£o m√∫ltipla** passa a ser a estrat√©gia recomendada.\n",
    "\n",
    "Aplicando isso ao nosso conjunto:\n",
    "\n",
    "* `ESCS` ‚âà **2.2%** faltantes ‚Üí\n",
    "  Excluir esses casos √© aceit√°vel: a perda √© pequena, e, de todo modo, sem `ESCS` o aluno n√£o pode contribuir para o gradiente socioecon√¥mico. Nesse contexto, a exclus√£o n√£o distorce o estimando, apenas reduz ligeiramente o n √∫til.\n",
    "\n",
    "* `DISCLIMA` ‚âà **5.4%** ‚Üí\n",
    "  Estamos na fronteira. Exclus√£o pura √© poss√≠vel, mas j√° come√ßa a ser discut√≠vel, principalmente porque `DISCLIMA` √© uma vari√°vel-chave.\n",
    "\n",
    "* `JOYREAD` ‚âà **9.7%**, \n",
    "* `SCREADCOMP` ‚âà **14.9%**, \n",
    "* `BELONG` ‚âà **22.7%** ‚Üí\n",
    "  Aqui, a exclus√£o massiva seria metodologicamente cara, j√° que reduziria o tamanho da amostra, concentraria a an√°lise em perfis mais completos (e possivelmente mais favorecidos) e aumentaria o risco de vi√©s de sele√ß√£o. Nesses casos, manter ‚Äúquem n√£o respondeu‚Äù como se n√£o existisse √©, na melhor das hip√≥teses, ing√™nuo. Logo, tudo isso justifica nossa op√ß√£o final: **imputa√ß√£o m√∫ltipla** para esses √≠ndices psicossociais.\n",
    "\n",
    "Mas na pr√°tica, o que significa isso? Significa que **respeitaremos a estrutura dos dados** utilizando informa√ß√µes de aluno, escola, desempenho (`READ`), contexto (`ESCS`), clima (`DISCLIMA`), atitudes (`JOYREAD`, `SCREADCOMP`, `BELONG`), repet√™ncia e vari√°veis de n√≠vel escola para gerar valores plaus√≠veis para os ausentes; **preservaremos variabilidade e rela√ß√µes**, j√° que ao inv√©s de substituir tudo por uma m√©dia √∫nica, geraremos v√°rias vers√µes imputadas do banco, incorporando incertezas, de tal modo que as estimativas finais reflitam tanto a variabilidade quanto a incerteza sobre os valores imputados e, finalmente, continuaremos alinhados com a pr√°tica metodol√≥gica consolidada em avalia√ß√£o educacional, haja vista o compromisso entre rigor estat√≠stico e o respeito √†s nuances dos dados, √† redu√ß√£o de vi√©s sem sacrificar a estrutura hier√°rquica nem a interpretabilidade dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8c2418a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Vari√°veis com ausentes que ser√£o imputadas\n",
    "vars_impute = [\"ESCS\", \"DISCLIMA\", \"JOYREAD\", \"SCREADCOMP\", \"BELONG\"]\n",
    "\n",
    "# Vari√°veis preditoras: n√£o ser√£o imputadas nem alteradas conceitualmente\n",
    "vars_aux = [\n",
    "    \"READ\", \"SENWT\",\n",
    "    \"REPEAT\",        # j√° codificada (0,1,2) ou 0/1, completa\n",
    "    \"ST004D01T\",     # j√° codificada (0/1), completa\n",
    "]\n",
    "\n",
    "# Matriz para o IterativeImputer:\n",
    "# As colunas em vars_impute t√™m NA\n",
    "# As colunas em vars_aux entram como preditores (sem NA)\n",
    "\n",
    "X = students[vars_impute + vars_aux]\n",
    "\n",
    "imp = IterativeImputer(\n",
    "    max_iter=20,\n",
    "    sample_posterior=True,   # essencial para m√∫ltiplas imputa√ß√µes\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "m = 20\n",
    "imputations = []\n",
    "\n",
    "for s in range(m):\n",
    "    # nova semente a cada imputa√ß√£o\n",
    "    imp.random_state = 123 + s\n",
    "    \n",
    "    # ajusta o modelo e imputa SOMENTE onde h√° NaN\n",
    "    X_imp = imp.fit_transform(X)\n",
    "    \n",
    "    # cria c√≥pia do dataframe original\n",
    "    students_imp = students.copy()\n",
    "\n",
    "    # sobrescreve apenas as vari√°veis imputadas com os valores imputados (nas posi√ß√µes correspondentes)\n",
    "    students_imp[vars_impute] = X_imp[:, :len(vars_impute)]\n",
    "    \n",
    "    # garante que REPEAT e ST004D01T continuem categ√≥ricos como definidos\n",
    "    students_imp[\"REPEAT\"] = students_imp[\"REPEAT\"].astype(students[\"REPEAT\"].dtype)\n",
    "    students_imp[\"ST004D01T\"] = students_imp[\"ST004D01T\"].astype(students[\"ST004D01T\"].dtype)\n",
    "    \n",
    "    imputations.append(students_imp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7459ca86",
   "metadata": {},
   "source": [
    "Como de constume, vamos conferir a parada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fccadd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNTSTUID      0\n",
       "CNTSCHID      0\n",
       "ST004D01T     0\n",
       "REPEAT        0\n",
       "ESCS          0\n",
       "DISCLIMA      0\n",
       "BELONG        0\n",
       "JOYREAD       0\n",
       "SCREADCOMP    0\n",
       "SENWT         0\n",
       "READ          0\n",
       "READ.SE       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_imp.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e057b",
   "metadata": {},
   "source": [
    "## As vari√°veis de n√≠vel 2: Escola\n",
    "\n",
    "At√© agora trabalhamos apenas com vari√°veis de **n√≠vel aluno** (`ESCS`, g√™nero, repet√™ncia, clima disciplinar etc.). Isso √© suficiente para modelos ‚Äúcl√°ssicos‚Äù de regress√£o, mas insuficiente quando queremos levar a s√©rio o fato √≥bvio (embora frequentemente ignorado nas an√°lises) de que **alunos est√£o agrupados em escolas**. Para capturar esse contexto, precisamos trazer para o dataset dos alunos informa√ß√µes da escola onde eles estudam. Por conta disso, incorporamos ao modelo vari√°veis de **n√≠vel escola**, extra√≠das da planilha `SCH_BRA.xlsx`, de modo a respeitar a estrutura hier√°rquica dos dados.\n",
    "\n",
    "A base `SCH_BRA.xlsx` fornece, para cada `CNTSCHID`, √≠ndices de contexto escolar, entre os quais destacamos:\n",
    "\n",
    "- `EDUSHORT` e `STAFFSHORT`: √≠ndices constru√≠dos a partir das respostas dos diretores sobre escassez de materiais pedag√≥gicos e de pessoal qualificado. Nos microdados, esses √≠ndices s√£o armazenados em uma escala deslocada, semelhante ao que vimos em `FLT`. Aplicamos, portanto, a transforma√ß√£o inversa (`/10 - 5`) para obter `edushort_std` e `staffshort_std`, aproximadamente centrados em 0. Valores positivos indicam maior escassez que a m√©dia da OCDE; valores negativos indicam menor escassez (condi√ß√µes mais favor√°veis).\n",
    "\n",
    "- `SC016Q01TA` e `SC016Q02TA`: percentuais da receita escolar provenientes, respectivamente, de fontes governamentais e de contribui√ß√µes privadas (fam√≠lias, doadores, patroc√≠nios), o que nos permite caracterizar a composi√ß√£o do financiamento escolar.\n",
    "\n",
    "Por constru√ß√£o, essas vari√°veis comp√µem o **n√≠vel 2** dos modelos, enquanto `ESCS`, g√™nero, repet√™ncia, clima disciplinar, atitudes e profici√™ncia permanecem no **n√≠vel 1** (aluno). A jun√ß√£o entre bases nos permite separar o que √© efeito das **caracter√≠sticas individuais dos estudantes** do que √© efeito das **condi√ß√µes das escolas**, al√©m de testar se o contexto escolar amplifica, atenua ou modifica o gradiente socioecon√¥mico associado ao `ESCS`. Sem essas vari√°veis de n√≠vel escola, qualquer infer√™ncia sobre ‚Äúimpacto da escola‚Äù tenderia a confundir diferen√ßas de composi√ß√£o (quem estuda onde) com diferen√ßas reais de oportunidade educacional.\n",
    "\n",
    "\n",
    "Ante, por√©m, vamos conferir os dados ausentes e reescalonar os √≠ndices WLE conforme necess√°rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fd63e062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNTSCHID        0\n",
       "SC016Q01TA     59\n",
       "SC016Q02TA    172\n",
       "EDUSHORT       42\n",
       "STAFFSHORT     45\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4c7bb",
   "metadata": {},
   "source": [
    "Antes de incorporar as vari√°veis de n√≠vel escola ao dataset de alunos, avaliamos o padr√£o de dados ausentes em `SCH_BRA.xlsx`. Entre as 597 escolas, observamos:\n",
    "\n",
    "- `SC016Q01TA`: 59 ausentes ‚Üí ‚âà 9,9%\n",
    "- `SC016Q02TA`: 172 ausentes ‚Üí ‚âà 28,8%\n",
    "- `EDUSHORT`: 42 ausentes ‚Üí ‚âà 7,0%\n",
    "- `STAFFSHORT`: 45 ausentes ‚Üí ‚âà 7,5%\n",
    "\n",
    "Retomando nossa r√©gua de decis√£o: at√© ‚âà5% de ausentes, a exclus√£o de casos tende a ser aceit√°vel; entre 5% e 10%, a exclus√£o j√° exige cautela e a imputa√ß√£o passa a ser uma alternativa razo√°vel; acima de 10%, a exclus√£o sistem√°tica costuma induzir vieses relevantes e perda desnecess√°ria de informa√ß√£o.\n",
    "\n",
    "Aplicando esse crit√©rio ao contexto escolar:\n",
    "\n",
    "- Para `EDUSHORT` e `STAFFSHORT` (7‚Äì8% de ausentes), a exclus√£o n√£o seria absurda, mas, por se tratarem de vari√°veis centrais para caracterizar recursos e condi√ß√µes de oferta, preferimos n√£o descartar escolas. A op√ß√£o metodologicamente mais consistente tamb√©m parece ser trat√°-las com **imputa√ß√£o m√∫ltipla**, preservando o desenho hier√°rquico.\n",
    "  \n",
    "- Para `SC016Q01TA` (~10% de ausentes), estamos na borda superior da zona de conforto. A imputa√ß√£o m√∫ltipla √© defens√°vel, sobretudo porque a vari√°vel tem interpreta√ß√£o clara (financiamento governamental) e potencial explicativo relevante no n√≠vel escola.\n",
    "  \n",
    "- J√° `SC016Q02TA` (~28,8% de ausentes) acende um alerta mais forte. Quase um ter√ßo das escolas n√£o informa a parcela de financiamento privado, o que implica:\n",
    "  - forte depend√™ncia das imputa√ß√µes em rela√ß√£o ao modelo especificado e √†s suposi√ß√µes de *MAR*;\n",
    "  - alta fra√ß√£o de informa√ß√£o perdida associada a essa vari√°vel, produzindo estimativas mais inst√°veis (erros-padr√£o maiores, intervalos de confian√ßa mais largos, maior sensibilidade a pequenas mudan√ßas no modelo).\n",
    "  \n",
    "Em outras palavras, `SC016Q02TA` pode ser imputada, mas qualquer conclus√£o substantiva apoiada nela carrega incerteza adicional. Por isso, optamos por trat√°-la principalmente como **vari√°vel de an√°lise de sensibilidade**, e n√£o como pilar do modelo principal: usamos sua inclus√£o ou exclus√£o (com imputa√ß√£o) para verificar se os resultados centrais se mant√™m robustos, em vez de basear infer√™ncias fortes em uma covari√°vel com alta propor√ß√£o de valores imputados.\n",
    "\n",
    "Um ponto t√©cnico importante √© que essa decis√£o √© tomada **antes** do `merge` com o n√≠vel aluno. Caso contr√°rio, cada escola com dados ausentes em `EDUSHORT`, `STAFFSHORT` ou nos indicadores de financiamento propagaria *NaN* para todos os seus alunos, inflando artificialmente a taxa de aus√™ncia no n√≠vel 1. Trat√°-los, portanto, se mostra essencial para preservar a integridade da estrutura hier√°rquica e reduzir vieses na etapa de modelagem.\n",
    "\n",
    "S√≥  para registrar: ‚Äúadotamos abaixo imputa√ß√£o m√∫ltipla com m = 20, de modo a representar adequadamente a incerteza associada aos dados ausentes, em vez de tratar a imputa√ß√£o como se gerasse valores ‚Äòcertos‚Äô.‚Äù \n",
    "\n",
    "Mas antes disso, vamos fazer uma c√≥pia de seguran√ßa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a8907918",
   "metadata": {},
   "outputs": [],
   "source": [
    "sch_raw = sch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "248130c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sch = sch_raw.copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150c62b6",
   "metadata": {},
   "source": [
    "Imputando, reescalando e renomeando as vari√°veis de n√≠vel escola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ffaf43d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vari√°veis a imputar em n√≠vel escola\n",
    "vars_impute = [\"SC016Q01TA\", \"SC016Q02TA\", \"EDUSHORT\", \"STAFFSHORT\"]\n",
    "\n",
    "X_sch = sch[vars_impute]\n",
    "\n",
    "imp_sch = IterativeImputer(\n",
    "    max_iter=20,\n",
    "    sample_posterior=True,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "m = 20  # n√∫mero de bancos imputados\n",
    "sch_imputations = []\n",
    "\n",
    "for k in range(m):\n",
    "    imp_sch.random_state = 123 + k\n",
    "    \n",
    "    # Imputando SC016Q01TA, SC016Q02TA, EDUSHORT, STAFFSHORT\n",
    "    X_sch_imp = imp_sch.fit_transform(X_sch)\n",
    "    \n",
    "    sch_imp_k = sch.copy()\n",
    "    sch_imp_k[vars_impute] = X_sch_imp\n",
    "\n",
    "    # Reescalando EDUSHORT e STAFFSHORT (agora j√° imputados)\n",
    "    sch_imp_k[\"EDUSHORT_std\"]   = sch_imp_k[\"EDUSHORT\"] / 10 - 5\n",
    "    sch_imp_k[\"STAFFSHORT_std\"] = sch_imp_k[\"STAFFSHORT\"] / 10 - 5\n",
    "\n",
    "    sch_imputations.append(sch_imp_k)\n",
    "\n",
    "sch_imp = sch_imputations[0].copy()\n",
    "\n",
    "# Substituir as colunas originais pelas vers√µes padronizadas para manter o mesmo esquema de nomes\n",
    "\n",
    "sch_imp = (\n",
    "    sch_imp\n",
    "    .drop(columns=[\"EDUSHORT\", \"STAFFSHORT\"])  # remove escala deslocada\n",
    "    .rename(columns={\n",
    "        \"EDUSHORT_std\": \"EDUSHORT\",\n",
    "        \"STAFFSHORT_std\": \"STAFFSHORT\"\n",
    "    })[[\"CNTSCHID\", \"SC016Q01TA\", \"SC016Q02TA\", \"EDUSHORT\", \"STAFFSHORT\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb216099",
   "metadata": {},
   "source": [
    "Conferindo se funcionou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "88396e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNTSCHID      0\n",
       "SC016Q01TA    0\n",
       "SC016Q02TA    0\n",
       "EDUSHORT      0\n",
       "STAFFSHORT    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch_imp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "21fa0a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNTSCHID</th>\n",
       "      <th>SC016Q01TA</th>\n",
       "      <th>SC016Q02TA</th>\n",
       "      <th>EDUSHORT</th>\n",
       "      <th>STAFFSHORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7600001</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.300</td>\n",
       "      <td>4.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7600002</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6.400</td>\n",
       "      <td>1.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7600003</td>\n",
       "      <td>2.688</td>\n",
       "      <td>19.000</td>\n",
       "      <td>-4.900</td>\n",
       "      <td>-4.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7600005</td>\n",
       "      <td>1.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>-4.900</td>\n",
       "      <td>-3.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7600006</td>\n",
       "      <td>17.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-4.800</td>\n",
       "      <td>-4.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNTSCHID  SC016Q01TA  SC016Q02TA  EDUSHORT  STAFFSHORT\n",
       "0   7600001      20.000       1.000     4.300       4.800\n",
       "1   7600002      20.000       1.000     6.400       1.800\n",
       "2   7600003       2.688      19.000    -4.900      -4.800\n",
       "3   7600005       1.000      19.000    -4.900      -3.400\n",
       "4   7600006      17.000       1.000    -4.800      -4.800"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch_imp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c38950",
   "metadata": {},
   "source": [
    "Agora que j√° reescalonamos e renomeamos as vari√°veis de n√≠vel escola, podemos incorpor√°-las ao dataset de alunos via `CNTSCHID`. Assim como antes, usaremos `validate=\"many_to_one\"` para garantir que cada escola seja vinculada corretamente aos seus alunos, sem duplica√ß√µes inesperadas. Contudo, vamos examinar se h√° alguma discrep√¢ncia entre as escolas listadas em `students` e aquelas presentes em `schools`, fazendo um merge preliminar com `how=\"outer\"`.\n",
    "\n",
    "Observa√ß√£o. No processo de imputa√ß√£o geramos um dataframe chamado `sch_imp` e √© esse que usaremos para o merge. Entretanto, para fins de informa√ß√£o, usaremos o nome do dataframe original `sch`, apenas para facilitar o entendimento do resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f8087609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVALIA√á√ÉO DO MERGE STUDENTS x SCH\n",
      "\n",
      "Dimens√µes atuais:\n",
      "   ‚Ä¢ students : 4,908 linhas √ó 12 colunas\n",
      "   ‚Ä¢ sch  : 597 linhas √ó 5 colunas\n",
      "\n",
      "N√£o h√° escolas repetidas.\n",
      "\n",
      "Resumo do merge:\n",
      "   ‚Ä¢ Escolas combinadas:: 4,908 (99.80%)\n",
      "   ‚Ä¢ Apenas em sch (escola sem aluno em students): 10 (0.20%)\n",
      "\n",
      "Cobertura por escola:\n",
      "   ‚Ä¢ Escolas presentes em ambos (com alunos): 587\n",
      "   ‚Ä¢ Escolas s√≥ em students                : 0\n",
      "   ‚Ä¢ Escolas s√≥ em sch (sem alunos)    : 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"AVALIA√á√ÉO DO MERGE STUDENTS x SCH\\n\")\n",
    "\n",
    "print(\"Dimens√µes atuais:\")\n",
    "print(f\"   ‚Ä¢ students : {students_imp.shape[0]:,} linhas √ó {students_imp.shape[1]} colunas\")\n",
    "print(f\"   ‚Ä¢ sch  : {sch_imp.shape[0]:,} linhas √ó {sch_imp.shape[1]} colunas\\n\")\n",
    "\n",
    "# CNTSCHID apenas em sch\n",
    "dups_sch = sch_imp[\"CNTSCHID\"].duplicated().sum()\n",
    "if dups_sch == 0:\n",
    "    print(\"N√£o h√° escolas repetidas.\")\n",
    "else:\n",
    "    print(f\"ATEN√á√ÉO! H√° {dups_sch} escolas repetidas.\")\n",
    "print()\n",
    "\n",
    "merge_diag = students_imp.merge(\n",
    "    sch_imp,\n",
    "    on=\"CNTSCHID\",\n",
    "    how=\"outer\",\n",
    "    indicator=True,\n",
    "    suffixes=(\"_stu\", \"_sch\")\n",
    ")\n",
    "\n",
    "# Ordenando os status para impress√£o consistente\n",
    "status_labels = {\n",
    "    \"both\": \"Escolas combinadas:\",\n",
    "    \"left_only\": \"Apenas em students (aluno sem escola em sch)\",\n",
    "    \"right_only\": \"Apenas em sch (escola sem aluno em students)\"\n",
    "}\n",
    "\n",
    "print(\"Resumo do merge:\")\n",
    "total = len(merge_diag)\n",
    "for key in [\"both\", \"left_only\", \"right_only\"]:\n",
    "    if key in merge_diag[\"_merge\"].values:\n",
    "        count = (merge_diag[\"_merge\"] == key).sum()\n",
    "        pct = 100 * count / total\n",
    "        print(f\"   ‚Ä¢ {status_labels[key]}: {count:,} ({pct:.2f}%)\")\n",
    "print()\n",
    "\n",
    "# n√≠vel escola\n",
    "students_sch_ids = set(students[\"CNTSCHID\"].unique())\n",
    "sch_imp_ids      = set(sch_imp[\"CNTSCHID\"].unique())\n",
    "\n",
    "only_in_students = students_sch_ids - sch_imp_ids\n",
    "only_in_sch_imp  = sch_imp_ids - students_sch_ids\n",
    "both_ids         = students_sch_ids & sch_imp_ids\n",
    "\n",
    "print(\"Cobertura por escola:\")\n",
    "print(f\"   ‚Ä¢ Escolas presentes em ambos (com alunos): {len(both_ids)}\")\n",
    "print(f\"   ‚Ä¢ Escolas s√≥ em students                : {len(only_in_students)}\")\n",
    "print(f\"   ‚Ä¢ Escolas s√≥ em sch (sem alunos)    : {len(only_in_sch_imp)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356adef",
   "metadata": {},
   "source": [
    "Fazendo o merge definitivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a2d01510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4908, 16)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# many_to_one para garantir estrutura aluno -> escola\n",
    "students_merged = students_imp.merge(\n",
    "    sch_imp,\n",
    "    on=\"CNTSCHID\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "students_merged.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e82212a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNTSTUID</th>\n",
       "      <th>CNTSCHID</th>\n",
       "      <th>ST004D01T</th>\n",
       "      <th>REPEAT</th>\n",
       "      <th>ESCS</th>\n",
       "      <th>DISCLIMA</th>\n",
       "      <th>BELONG</th>\n",
       "      <th>JOYREAD</th>\n",
       "      <th>SCREADCOMP</th>\n",
       "      <th>SENWT</th>\n",
       "      <th>READ</th>\n",
       "      <th>READ.SE</th>\n",
       "      <th>SC016Q01TA</th>\n",
       "      <th>SC016Q02TA</th>\n",
       "      <th>EDUSHORT</th>\n",
       "      <th>STAFFSHORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7600001</td>\n",
       "      <td>7600614</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.647</td>\n",
       "      <td>0.320</td>\n",
       "      <td>16.008</td>\n",
       "      <td>1.230</td>\n",
       "      <td>-4.623</td>\n",
       "      <td>0.308</td>\n",
       "      <td>470.375</td>\n",
       "      <td>22.412</td>\n",
       "      <td>20.000</td>\n",
       "      <td>-0.511</td>\n",
       "      <td>1.251</td>\n",
       "      <td>-6.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7600002</td>\n",
       "      <td>7600190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.479</td>\n",
       "      <td>3.700</td>\n",
       "      <td>10.140</td>\n",
       "      <td>-3.060</td>\n",
       "      <td>-4.840</td>\n",
       "      <td>0.342</td>\n",
       "      <td>432.607</td>\n",
       "      <td>23.037</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.902</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>-4.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7600010</td>\n",
       "      <td>7600048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.273</td>\n",
       "      <td>-4.530</td>\n",
       "      <td>15.340</td>\n",
       "      <td>-2.640</td>\n",
       "      <td>-4.460</td>\n",
       "      <td>0.525</td>\n",
       "      <td>428.324</td>\n",
       "      <td>31.055</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.646</td>\n",
       "      <td>5.700</td>\n",
       "      <td>-0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7600020</td>\n",
       "      <td>7600444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.170</td>\n",
       "      <td>-1.870</td>\n",
       "      <td>11.850</td>\n",
       "      <td>-1.070</td>\n",
       "      <td>-4.650</td>\n",
       "      <td>0.658</td>\n",
       "      <td>378.231</td>\n",
       "      <td>24.029</td>\n",
       "      <td>18.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2.900</td>\n",
       "      <td>-3.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7600022</td>\n",
       "      <td>7600047</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.467</td>\n",
       "      <td>-4.370</td>\n",
       "      <td>3.920</td>\n",
       "      <td>-4.860</td>\n",
       "      <td>-4.520</td>\n",
       "      <td>0.511</td>\n",
       "      <td>419.672</td>\n",
       "      <td>16.979</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.486</td>\n",
       "      <td>-2.700</td>\n",
       "      <td>-4.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNTSTUID  CNTSCHID  ST004D01T  REPEAT   ESCS  DISCLIMA  BELONG  JOYREAD  \\\n",
       "0   7600001   7600614          1       0 -1.647     0.320  16.008    1.230   \n",
       "1   7600002   7600190          0       0  2.479     3.700  10.140   -3.060   \n",
       "2   7600010   7600048          0       0  1.273    -4.530  15.340   -2.640   \n",
       "3   7600020   7600444          1       1 -3.170    -1.870  11.850   -1.070   \n",
       "4   7600022   7600047          1       1 -3.467    -4.370   3.920   -4.860   \n",
       "\n",
       "   SCREADCOMP  SENWT    READ  READ.SE  SC016Q01TA  SC016Q02TA  EDUSHORT  \\\n",
       "0      -4.623  0.308 470.375   22.412      20.000      -0.511     1.251   \n",
       "1      -4.840  0.342 432.607   23.037      20.000       0.902    -2.900   \n",
       "2      -4.460  0.525 428.324   31.055      20.000       1.646     5.700   \n",
       "3      -4.650  0.658 378.231   24.029      18.000       1.000    -2.900   \n",
       "4      -4.520  0.511 419.672   16.979      20.000       1.486    -2.700   \n",
       "\n",
       "   STAFFSHORT  \n",
       "0      -6.755  \n",
       "1      -4.800  \n",
       "2      -0.200  \n",
       "3      -3.100  \n",
       "4      -4.800  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa42c04",
   "metadata": {},
   "source": [
    "Vamos adicionar mais um ponto de salvaguarda, criando uma c√≥pia do dataframe resultante do merge final, que chamaremos de `students_final`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4e784e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_final = students_merged.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bc2053",
   "metadata": {},
   "source": [
    "###  Perfil Agregado das Escolas\n",
    "\n",
    "At√© este ponto, trabalhamos exclusivamente com vari√°veis no n√≠vel do aluno (`ESCS`, `READ`, `g√™nero`, `repet√™ncia`, `clima disciplinar` etc.). Embora essas informa√ß√µes sejam fundamentais para caracterizar trajet√≥rias individuais, elas n√£o capturam diretamente o contexto institucional no qual os estudantes est√£o inseridos. Para operacionalizar o conceito de \"efeito escola\" em termos observ√°veis, precisamos agregar caracter√≠sticas dos alunos por escola, traduzindo a heterogeneidade institucional em m√©tricas concretas: desempenho m√©dio, perfil socioecon√¥mico m√©dio, clima disciplinar m√©dio, entre outras.\n",
    "\n",
    "Essa etapa cumpre tr√™s fun√ß√µes metodol√≥gicas centrais:\n",
    "\n",
    "- Constru√ß√£o de vari√°veis de n√≠vel 2 (escola): Ao calcular m√©dias ponderadas de `READ`, `ESCS`, `DISCLIMA` e `BELONG` para cada `CNTSCHID`, geramos covari√°veis agregadas que podem ser incorporadas aos modelos multin√≠veis. Isso permite separar o efeito das caracter√≠sticas individuais (n√≠vel 1) do efeito das condi√ß√µes da escola (n√≠vel 2).\n",
    "\n",
    "- Respeito ao desenho amostral do PISA: Utilizamos `SENWT` (peso amostral do estudante) como fator de expans√£o. Como escolas e alunos s√£o amostrados com probabilidades distintas, aplicar pondera√ß√£o nas agrega√ß√µes garante que as m√©dias escolares reflitam a popula√ß√£o-alvo (estudantes brasileiros de 15 anos matriculados em escolas regulares), e n√£o apenas a amostra observada. Uma m√©dia simples trataria igualmente um aluno que representa 10 estudantes da popula√ß√£o e outro que representa 200, distorcendo as estimativas.\n",
    "\n",
    "- Fundamenta√ß√£o para hip√≥teses substantivas: Perguntas como \"escolas com maior `ESCS` m√©dio apresentam melhor desempenho, mesmo ap√≥s controlar o `ESCS` individual?\" ou \"o clima disciplinar m√©dio da escola modera o gradiente socioecon√¥mico?\" s√≥ podem ser respondidas se tivermos acesso a essas vari√°veis agregadas. Sem elas, qualquer infer√™ncia sobre \"efeito escola\" tenderia a confundir diferen√ßas de composi√ß√£o (quem estuda onde) com diferen√ßas reais de oportunidade educacional.\n",
    "\n",
    "Para cada escola (CNTSCHID), geramos cinco m√©tricas ponderadas por `SENWT`:\n",
    "\n",
    "| M√©trica         | Descri√ß√£o                     | Interpreta√ß√£o                                             |\n",
    "| --------------- | ----------------------------- | --------------------------------------------------------- |\n",
    "| n_students      | Contagem de alunos na amostra | Tamanho da escola na base (n√£o ponderado)                 |\n",
    "| read_mean_w     | Profici√™ncia m√©dia em leitura | Desempenho m√©dio da escola (escala PISA: ~500 ¬± 100)      |\n",
    "| escs_mean_w     | √çndice socioecon√¥mico m√©dio   | Contexto socioecon√¥mico do corpo discente (centrado em 0) |\n",
    "| disclima_mean_w | Clima disciplinar m√©dio       | Qualidade do ambiente escolar percebida pelos alunos      |\n",
    "| belong_mean_w   | Pertencimento m√©dio           | Senso de comunidade e acolhimento (escala 0‚Äì10)           |\n",
    "\n",
    "\n",
    "Exemplo da l√≥gica da Pondera√ß√£o:\n",
    "\n",
    "Situa√ß√£o hipot√©tica: uma escola tem 3 alunos na amostra:\n",
    "\n",
    "| Aluno | READ | SENWT |\n",
    "| ----- | ---- | ----- |\n",
    "| A     | 420  | 100   |\n",
    "| B     | 450  | 50    |\n",
    "| C     | 500  | 25    |\n",
    "\n",
    "#### M√©dia simples (**incorreta**)\n",
    "\n",
    "$$\n",
    "\\bar{x}_{\\text{simples}} = \\frac{420 + 450 + 500}{3} = 456{,}67\n",
    "$$\n",
    "\n",
    "#### M√©dia ponderada (**correta**)\n",
    "\n",
    "$$\n",
    "\\bar{x}_{\\text{pond}} =\n",
    "\\frac{420 \\cdot 100 + 450 \\cdot 50 + 500 \\cdot 25}{100 + 50 + 25}\n",
    "= \\frac{42000 + 22500 + 12500}{175}\n",
    "= \\frac{77000}{175}\n",
    "= 440\n",
    "$$\n",
    "\n",
    "\n",
    "#### Interpreta√ß√£o\n",
    "\n",
    "O aluno A representa 4 vezes mais estudantes na popula√ß√£o do que o aluno C.\n",
    "Se ignorarmos os pesos amostrais (SENWT), superestimamos o desempenho m√©dio da escola, pois tratamos como equivalentes observa√ß√µes que t√™m import√¢ncias muito diferentes no plano amostral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d061bf5",
   "metadata": {},
   "source": [
    "Para implementar isso, utilizamos a fun√ß√£o `groupby(\"CNTSCHID\")` para organizar os dados em grupos de alunos por escola. Em cada grupo, aplicamos a fun√ß√£o `estat.wavg(valor, w=SENWT)` para calcular m√©dias ponderadas com os pesos amostrais dos estudantes. Isso garante que cada m√©dia reflita n√£o apenas os alunos da amostra, mas a popula√ß√£o de estudantes que eles representam. O resultado √© um DataFrame de perfil escolar com uma linha por escola, contendo indicadores como tamanho da amostra (`n_students`), profici√™ncia m√©dia ponderada em leitura (`read_mean_w`), n√≠vel socioecon√¥mico m√©dio (`escs_mean_w`), clima disciplinar (`disclima_mean_w`) e pertencimento (`belong_mean_w`). Esse perfil ser√°, ent√£o, mesclado ao dataset de alunos, para ser utilizado como um conjunto de vari√°veis de contexto em n√≠vel da escola.\n",
    "\n",
    "Depois de refletir sobre a pondera√ß√£o, conclu√≠mos que mesmo os √≠ndices derivados, como o `ESCS`, calculados originalmente em n√≠vel do estudante, devem ser ponderados ao agreg√°-los para o n√≠vel da escola. Para obter o \"ESCS m√©dio da escola\", utilizamos a m√©dia ponderada pelos pesos dos alunos daquela escola, por exemplo:\n",
    "\n",
    "$$\n",
    "ESCS_{\\text{escola}} =\n",
    "\\frac{\\sum_{i \\in \\text{escola}} SENWT_i \\cdot ESCS_i}\n",
    "     {\\sum_{i \\in \\text{escola}} SENWT_i}\n",
    "$$\n",
    "\n",
    "O mesmo racioc√≠nio se aplica a escalas como clima disciplinar e pertencimento: ponderar por `SENWT` evita que um subconjunto at√≠pico de respondentes distor√ßa o perfil da escola, assegurando que os indicadores contextuais usados nas an√°lises reflitam adequadamente a popula√ß√£o-alvo do PISA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "52e29e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNTSCHID</th>\n",
       "      <th>n_students</th>\n",
       "      <th>read_mean_w</th>\n",
       "      <th>escs_mean_w</th>\n",
       "      <th>disclima_mean_w</th>\n",
       "      <th>belong_mean_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7600001</td>\n",
       "      <td>8.000</td>\n",
       "      <td>329.420</td>\n",
       "      <td>-0.942</td>\n",
       "      <td>0.354</td>\n",
       "      <td>8.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7600002</td>\n",
       "      <td>9.000</td>\n",
       "      <td>427.369</td>\n",
       "      <td>-1.052</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>6.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7600003</td>\n",
       "      <td>1.000</td>\n",
       "      <td>319.741</td>\n",
       "      <td>0.716</td>\n",
       "      <td>2.090</td>\n",
       "      <td>11.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7600005</td>\n",
       "      <td>12.000</td>\n",
       "      <td>548.127</td>\n",
       "      <td>2.991</td>\n",
       "      <td>0.140</td>\n",
       "      <td>10.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7600006</td>\n",
       "      <td>8.000</td>\n",
       "      <td>400.459</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>-0.590</td>\n",
       "      <td>10.425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNTSCHID  n_students  read_mean_w  escs_mean_w  disclima_mean_w  \\\n",
       "0   7600001       8.000      329.420       -0.942            0.354   \n",
       "1   7600002       9.000      427.369       -1.052           -0.956   \n",
       "2   7600003       1.000      319.741        0.716            2.090   \n",
       "3   7600005      12.000      548.127        2.991            0.140   \n",
       "4   7600006       8.000      400.459       -0.808           -0.590   \n",
       "\n",
       "   belong_mean_w  \n",
       "0          8.127  \n",
       "1          6.130  \n",
       "2         11.684  \n",
       "3         10.795  \n",
       "4         10.425  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school_profile = (\n",
    "    students_final\n",
    "    .groupby(\"CNTSCHID\", as_index=False)\n",
    "    .apply(\n",
    "        lambda df: pd.Series({\n",
    "            \"n_students\": len(df),\n",
    "            \"read_mean_w\": estat.wavg(df[\"READ\"], df[\"SENWT\"]),\n",
    "            \"escs_mean_w\": estat.wavg(df[\"ESCS\"], df[\"SENWT\"]),\n",
    "            \"disclima_mean_w\": estat.wavg(df[\"DISCLIMA\"], df[\"SENWT\"]),\n",
    "            \"belong_mean_w\": estat.wavg(df[\"BELONG\"], df[\"SENWT\"]),\n",
    "        }),\n",
    "        include_groups=False \n",
    "    )\n",
    ")\n",
    "\n",
    "school_profile.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d9c157",
   "metadata": {},
   "source": [
    "\n",
    "Vamos entender o significado de cada m√©trica gerada no perfil agregado das escolas:\n",
    "\n",
    "* **CNTSCHID**: √â o identificador da escola no PISA. Serve apenas para saber ‚Äúde qual escola √© esta linha‚Äù. N√£o √© m√©trica substantiva.\n",
    "\n",
    "* **n_students**: √â a quantidade de alunos da amostra naquela escola (contagem simples de linhas).\n",
    "  **Interpreta√ß√£o:** tamanho da amostra escolar no banco, n√£o √© n√∫mero real de alunos da escola na popula√ß√£o; √© ‚Äúquantos casos temos para estimar‚Äù.\n",
    "\n",
    "* **read_mean_w**: √â a m√©dia ponderada da profici√™ncia em leitura dos alunos da escola. Usa os pesos amostrais (SENWT), ent√£o respeita o plano amostral do PISA.\n",
    "  **Escala:** PISA (m√©dia ‚âà 500, desvio ‚âà 100).\n",
    "  Ex.: 329 indica desempenho bem abaixo da m√©dia internacional.\n",
    "\n",
    "* **escs_mean_w**: √â a m√©dia ponderada do √≠ndice socioecon√¥mico (ESCS) dos alunos da escola.\n",
    "  **Escala:** centrada em 0 (0 ‚âà m√©dia dos pa√≠ses da OCDE; valores negativos = contexto menos favorecido; positivos = contexto mais favorecido).\n",
    "  Ex.: -0.942 sugere escola com alunos em contexto socioecon√¥mico mais baixo.\n",
    "\n",
    "* **disclima_mean_w**: √â a m√©dia ponderada do √≠ndice de clima disciplinar percebido pelos alunos.\n",
    "  Geralmente √© um √≠ndice padronizado (em torno de 0), onde valores maiores indicam clima mais organizado e menos problemas disciplinares; negativos indicam pior clima que a refer√™ncia.\n",
    "  Ex.: -0.956 sugere percep√ß√£o de problemas de disciplina acima do esperado.\n",
    "\n",
    "* **belong_mean_w**: √â a m√©dia ponderada do √≠ndice de pertencimento (sense of belonging).\n",
    "  **Escala t√≠pica:** algo como 0‚Äì10 (dependendo da constru√ß√£o, mas aqui j√° est√° em m√©trica interpret√°vel pela pr√≥pria documenta√ß√£o).\n",
    "  Valores maiores indicam maior sensa√ß√£o de acolhimento, integra√ß√£o e identifica√ß√£o com a escola.\n",
    "  Ex.: 6.130 vs 10.795 ‚Üí escolas com n√≠veis bem distintos de v√≠nculo percebido pelos alunos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2baca8b",
   "metadata": {},
   "source": [
    "### Anexar perfil de escola ao n√≠vel aluno\n",
    "\n",
    "Agora que temos o perfil agregado das escolas, podemos incorpor√°-lo ao dataset de alunos via `CNTSCHID`. Isso nos permitir√° incluir vari√°veis de contexto escolar em nossos modelos multin√≠veis, enriquecendo a an√°lise do efeito escola sobre o desempenho em leitura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7392f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_final = students_final.merge(\n",
    "    school_profile,\n",
    "    on=\"CNTSCHID\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "df65a68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNTSTUID</th>\n",
       "      <th>CNTSCHID</th>\n",
       "      <th>READ</th>\n",
       "      <th>ESCS</th>\n",
       "      <th>read_mean_w</th>\n",
       "      <th>escs_mean_w</th>\n",
       "      <th>disclima_mean_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7600001</td>\n",
       "      <td>7600614</td>\n",
       "      <td>470.375</td>\n",
       "      <td>-1.647</td>\n",
       "      <td>455.001</td>\n",
       "      <td>0.052</td>\n",
       "      <td>1.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7600002</td>\n",
       "      <td>7600190</td>\n",
       "      <td>432.607</td>\n",
       "      <td>2.479</td>\n",
       "      <td>483.699</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7600010</td>\n",
       "      <td>7600048</td>\n",
       "      <td>428.324</td>\n",
       "      <td>1.273</td>\n",
       "      <td>428.311</td>\n",
       "      <td>-1.893</td>\n",
       "      <td>2.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7600020</td>\n",
       "      <td>7600444</td>\n",
       "      <td>378.231</td>\n",
       "      <td>-3.170</td>\n",
       "      <td>399.373</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7600022</td>\n",
       "      <td>7600047</td>\n",
       "      <td>419.672</td>\n",
       "      <td>-3.467</td>\n",
       "      <td>342.109</td>\n",
       "      <td>-2.506</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CNTSTUID  CNTSCHID    READ   ESCS  read_mean_w  escs_mean_w  \\\n",
       "0   7600001   7600614 470.375 -1.647      455.001        0.052   \n",
       "1   7600002   7600190 432.607  2.479      483.699        0.895   \n",
       "2   7600010   7600048 428.324  1.273      428.311       -1.893   \n",
       "3   7600020   7600444 378.231 -3.170      399.373       -0.091   \n",
       "4   7600022   7600047 419.672 -3.467      342.109       -2.506   \n",
       "\n",
       "   disclima_mean_w  \n",
       "0            1.980  \n",
       "1            0.825  \n",
       "2            2.093  \n",
       "3           -0.853  \n",
       "4            0.132  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_final[[\n",
    "    \"CNTSTUID\", \"CNTSCHID\", \"READ\", \"ESCS\",\n",
    "    \"read_mean_w\", \"escs_mean_w\", \"disclima_mean_w\"\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2664a",
   "metadata": {},
   "source": [
    "#### Agora a brincadeira come√ßa: das m√©dias ao efeito escola\n",
    "\n",
    "Ao mesclar `school_profile` com `students_final`, cada linha passou a combinar informa√ß√µes individuais (`READ`, `ESCS`) com informa√ß√µes contextuais da escola (`read_mean_w`, `escs_mean_w`, `disclima_mean_w`) e essa estrutura nos permite distinguir duas dimens√µes fundamentais:\n",
    "\n",
    "1. **Quem estuda na escola** ‚Äì a composi√ß√£o dos alunos;\n",
    "2. **Que escola √© essa** ‚Äì o contexto e os poss√≠veis efeitos institucionais.\n",
    "\n",
    "E com isso, podemos investigar o tal **efeito escola**: escolas com `escs_mean_w` baixo mas `read_mean_w` alto, por exemplo, podem indicar um **efeito escola positivo**, por exemplo? Vejamos:\n",
    "\n",
    "#### 1. Composi√ß√£o: ‚ÄúQuem estuda aqui?‚Äù\n",
    "\n",
    "Considere duas escolas:\n",
    "\n",
    "* **Escola A**: maioria dos alunos com ESCS baixo.\n",
    "* **Escola B**: maioria dos alunos com ESCS alto.\n",
    "\n",
    "Se olharmos apenas para `read_mean_w` (profici√™ncia m√©dia em leitura), n√£o sabemos se a diferen√ßa entre A e B vem de:\n",
    "\n",
    "* caracter√≠sticas socioecon√¥micas dos alunos (**composi√ß√£o**),\n",
    "* pr√°ticas, recursos e clima da escola (**efeito escola**),\n",
    "* ou uma mistura das duas coisas.\n",
    "\n",
    "Para come√ßar a separar essas dimens√µes, precisamos ter ao mesmo tempo o **ESCS individual do aluno** ($ESCS_{ij}$) e o **ESCS m√©dio ponderado da escola** ($escs\\_mean_{w,j}$), que resume o contexto socioecon√¥mico dos alunos daquela escola.\n",
    "\n",
    "#### 2. Contexto e efeito escola: \"O que a escola faz/√©?\"\n",
    "\n",
    "A an√°lise ganha pot√™ncia quando usamos vari√°veis em dois n√≠veis no mesmo modelo: n√≠vel do aluno ($ESCS_{ij}$) e n√≠vel da escola ($escs\\_mean_{w,j}$).\n",
    "\n",
    "Um modelo <span title=\"Vamos olhar para um modelo multin√≠vel simplificado. Aqui estamos modelando a nota de leitura de um aluno i que estuda na escola j. Temos um intercepto, mais o efeito do ESCS individual do aluno, mais o efeito do ESCS m√©dio da escola, mais dois termos de erro: um no n√≠vel da escola e outro no n√≠vel do aluno. O que esses coeficientes significam? Beta 1 captura o efeito de diferen√ßas de ESCS entre alunos da mesma escola ‚Äî √© o efeito individual, tipo: se dois alunos estudam na mesma escola, mas um tem ESCS mais alto, quanto isso impacta na nota? J√° beta 2 √© mais interessante: ele captura o efeito de estudar em uma escola com ESCS m√©dio mais alto. Ou seja, mantendo fixo o ESCS individual do aluno, ser√° que estudar numa escola com colegas de contexto socioecon√¥mico mais alto faz diferen√ßa? Isso √© o que chamamos de efeito contextual ou efeito de composi√ß√£o. E por fim, temos o u_j, o efeito aleat√≥rio da escola. Depois de controlar pelo ESCS individual e pelo ESCS m√©dio da escola, ainda sobra algo? Esse res√≠duo √© frequentemente interpretado como parte do efeito escola propriamente dito ‚Äî o que a escola agrega al√©m da composi√ß√£o dos seus alunos.\"> multin√≠vel</span> simplificado pode ser escrito como:\n",
    "\n",
    "$$\n",
    "READ_{ij} =\n",
    "\\beta_0\n",
    "+ \\beta_1 \\cdot ESCS_{ij}\n",
    "+ \\beta_2 \\cdot escs\\_mean_{w,j}\n",
    "+ u_j\n",
    "+ e_{ij}\n",
    "$$\n",
    "\n",
    "onde:\n",
    "\n",
    "- $ESCS_{ij}$: capital socioecon√¥mico do aluno $i$ na escola $j$.\n",
    "- $escs\\_mean_{w,j}$ (**coluna `escs_mean_w`**), ou $\\overline{ESCS}^{(w)}_{j}$: ESCS m√©dio ponderado dos alunos da escola $j$.\n",
    "- $u_{j}$: efeito aleat√≥rio (desvio) da escola $j$ ap√≥s controlar pelos demais termos.\n",
    "- $e_{ij}$: erro individual do aluno $i$ na escola $j$.\n",
    "\n",
    "Interpreta√ß√µes t√≠picas:\n",
    "\n",
    "- $\\beta_{1}$: efeito de diferen√ßas de $ESCS$ **entre alunos da mesma escola** (efeito individual).\n",
    "- $\\beta_{2}$: efeito de estudar em uma escola com $escs\\_mean_{w,j}$ mais alto, mantendo fixo o $ESCS_{ij}$ (efeito contextual/composi√ß√£o).\n",
    "- $u_{j}$: componente residual em n√≠vel da escola, frequentemente interpretado como parte do **efeito escola** (o que a escola agrega al√©m da composi√ß√£o dos alunos).\n",
    "\n",
    "\n",
    "#### 3. Escolas com `escs_mean_w` baixo e `read_mean_w` alto\n",
    "\n",
    "Com os agregados dispon√≠veis, podemos investigar casos em que:\n",
    "\n",
    "* a escola tem `escs_mean_w` baixo (contexto socioecon√¥mico desfavor√°vel),\n",
    "* mas apresenta `read_mean_w` acima do valor esperado para esse contexto.\n",
    "\n",
    "Um procedimento simples:\n",
    "\n",
    "1. Calcular `escs_mean_w` (contexto socioecon√¥mico m√©dio ponderado da escola).\n",
    "2. Calcular `read_mean_w` (profici√™ncia m√©dia ponderada em leitura).\n",
    "3. Ajustar um modelo que prediga `read_mean_w` a partir de `escs_mean_w`.\n",
    "4. Observar os **res√≠duos** desse modelo.\n",
    "\n",
    "Escolas com res√≠duos positivos altos (desempenho muito acima do previsto pelo contexto) s√£o candidatas a apresentar um **efeito escola positivo** ‚Äî sugerem que oferecem condi√ß√µes, pr√°ticas ou ambientes que promovem aprendizagem al√©m do que seria esperado apenas pela composi√ß√£o socioecon√¥mica dos alunos.\n",
    "\n",
    "#### 4. Ligando com o DataFrame na pr√°tica\n",
    "\n",
    "Ao ter, em cada linha do `students_final`:\n",
    "\n",
    "* vari√°veis individuais (`READ`, `ESCS`);\n",
    "* vari√°veis contextuais da escola (`read_mean_w`, `escs_mean_w`, `disclima_mean_w`),\n",
    "\n",
    "voc√™ consegue:\n",
    "\n",
    "* separar efeitos **individuais** (quem √© o aluno) de efeitos **contextuais** (que escola ele frequenta);\n",
    "* identificar escolas que ‚Äúfogem da curva‚Äù, positiva ou negativamente;\n",
    "* especificar modelos multin√≠veis coerentes com o desenho amostral e com a distin√ß√£o entre composi√ß√£o e contexto.\n",
    "\n",
    "Sem esses agregados, qualquer conclus√£o sobre ‚Äúefeito escola‚Äù arrisca confundir **quem a escola atende** com **o que a escola efetivamente faz**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf3ef4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca3525e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d796d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03390634",
   "metadata": {},
   "source": [
    "## Estat√≠sticas Descritivas (ponderadas)\n",
    "\n",
    "Utilizamos `SENWT` para aproximar estimativas populacionais do PISA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ca14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_summary(df, column, weight):\n",
    "    clean = df.dropna(subset=[column, weight])\n",
    "    if clean.empty:\n",
    "        return {\"weighted_mean\": np.nan, \"weighted_sd\": np.nan, \"min\": np.nan, \"max\": np.nan, \"valid_n\": 0}\n",
    "    w = clean[weight]\n",
    "    values = clean[column]\n",
    "    mean = weighted_average(values, w)\n",
    "    var = weighted_average((values - mean) ** 2, w)\n",
    "    return {\n",
    "        \"weighted_mean\": mean,\n",
    "        \"weighted_sd\": np.sqrt(var),\n",
    "        \"min\": values.min(),\n",
    "        \"max\": values.max(),\n",
    "        \"valid_n\": len(values)\n",
    "    }\n",
    "\n",
    "summary_metrics = {\n",
    "    metric: weighted_summary(students, metric, \"SENWT\")\n",
    "    for metric in [\"READ\", \"escs_std\", \"disclima_std\"]\n",
    "}\n",
    "\n",
    "pd.DataFrame(summary_metrics).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f4c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribui√ß√£o das notas de leitura e do √≠ndice socioecon√¥mico\n",
    "sns.histplot(students.dropna(subset=[\"READ\"]), x=\"READ\", bins=30, color=\"#377eb8\")\n",
    "plt.title(\"Distribui√ß√£o de leitura (READ)\")\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(students.dropna(subset=[\"escs_std\"]), x=\"escs_std\", bins=30, color=\"#4daf4a\")\n",
    "plt.title(\"Distribui√ß√£o do √≠ndice socioecon√¥mico (ESCS)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa9a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradiente socioecon√¥mico com clima disciplinar como cor\n",
    "sample = students.dropna(subset=[\"READ\", \"escs_std\", \"disclima_std\"])\n",
    "if len(sample) > 3000:\n",
    "    sample = sample.sample(n=3000, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.scatterplot(\n",
    "    data=sample,\n",
    "    x=\"escs_std\",\n",
    "    y=\"READ\",\n",
    "    hue=\"disclima_std\",\n",
    "    palette=\"viridis\",\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.axhline(sample[\"READ\"].mean(), color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "plt.axvline(sample[\"escs_std\"].mean(), color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "plt.title(\"Leitura vs. ESCS (colora√ß√£o = clima disciplinar)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a3e7c7",
   "metadata": {},
   "source": [
    "## Modelos de Gradiente Socioecon√¥mico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45958cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = students.dropna(\n",
    "    subset=[\n",
    "        \"READ\", \"escs_std\", \"disclima_std\", \"edushort_std\", \"staffshort_std\",\n",
    "        \"gender_male\", \"repeat_flag\", \"SENWT\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "model1 = smf.wls(\n",
    "    formula=\"READ ~ escs_std\",\n",
    "    data=model_data,\n",
    "    weights=model_data[\"SENWT\"]\n",
    ").fit()\n",
    "\n",
    "model2 = smf.wls(\n",
    "    formula=(\n",
    "        \"READ ~ escs_std + disclima_std + edushort_std + staffshort_std \"\n",
    "        \"+ gender_male + repeat_flag + escs_std:edushort_std\"\n",
    "    ),\n",
    "    data=model_data,\n",
    "    weights=model_data[\"SENWT\"]\n",
    ").fit()\n",
    "\n",
    "print(model1.summary())\n",
    "print(model2.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4102792b",
   "metadata": {},
   "source": [
    "## Modelo Multin√≠vel e ICC\n",
    "\n",
    "Ajustamos um modelo com intercepto aleat√≥rio por escola para estimar o coeficiente de correla√ß√£o intraclasse (ICC), seguido por um modelo com inclina√ß√£o aleat√≥ria de ESCS e moderadores de n√≠vel escolar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_data = model_data.dropna(subset=[\"edushort_std\", \"staffshort_std\"]).copy()\n",
    "mixed_data[\"escs_centered\"] = mixed_data[\"escs_std\"] - mixed_data[\"escs_std\"].mean()\n",
    "\n",
    "null_model = smf.mixedlm(\n",
    "    formula=\"READ ~ 1\",\n",
    "    data=mixed_data,\n",
    "    groups=mixed_data[\"CNTSCHID\"]\n",
    ").fit()\n",
    "\n",
    "var_between = null_model.cov_re.iloc[0, 0]\n",
    "var_within = null_model.scale\n",
    "icc = var_between / (var_between + var_within)\n",
    "print(f\"ICC (modelo nulo): {icc:.3f}\")\n",
    "\n",
    "mixed_model = smf.mixedlm(\n",
    "    formula=\"READ ~ escs_centered + disclima_std + edushort_std + staffshort_std\",\n",
    "    data=mixed_data,\n",
    "    groups=mixed_data[\"CNTSCHID\"],\n",
    "    re_formula=\"~escs_centered\"\n",
    ").fit(method=\"lbfgs\")\n",
    "\n",
    "print(mixed_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc83ffec",
   "metadata": {},
   "source": [
    "## Observa√ß√µes Finais\n",
    "\n",
    "- Os identificadores do arquivo `FLT_BRA.xlsx` estavam deslocados em +50.000; o ajuste foi necess√°rio para casar com `STU_BRA.xlsx`.\n",
    "- √çndices armazenados como inteiros (ex.: `ESCS`, `DISCLIMA`, `EDUSHORT`) foram reescalados para as m√©tricas usuais antes das an√°lises.\n",
    "- As estimativas ponderadas indicam m√©dia de leitura em torno de 422 pontos e gradiente socioecon√¥mico positivo (~14,5 pontos por desvio de `ESCS`).\n",
    "- O ICC do modelo nulo (~0.44) aponta forte heterogeneidade entre escolas; a inclus√£o de clima disciplinar e escassez reduz a vari√¢ncia entre grupos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bee80d6",
   "metadata": {},
   "source": [
    "## Refer√™ncias\n",
    "\n",
    "- ORGANISATION FOR ECONOMIC CO-OPERATION AND DEVELOPMENT (OECD). *PISA 2018 Technical Report*. Paris: OECD Publishing, 2020. Dispon√≠vel em: `<https://www.oecd.org/pisa/data/pisa2018technicalreport/>`. Acesso em: 6 nov. 2025.\n",
    "\n",
    "- ORGANISATION FOR ECONOMIC CO-OPERATION AND DEVELOPMENT (OECD). *PISA 2018 Database*. Paris: OECD, 2019. Dispon√≠vel em: `<https://www.oecd.org/pisa/data/2018database/>`. Acesso em: 6 nov. 2025.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ianed-pf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
